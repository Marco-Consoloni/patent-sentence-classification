{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain Import\n",
    "from langchain.llms import OpenAI # for new models\n",
    "from langchain.chat_models import ChatOpenAI # for older models\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# Load OpenaAI API key\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def classify_sentence_chatgpt(input_text, template, model=\"gpt-4o\"):\n",
    "    \n",
    "    # Define a prompt template for classification\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    # Create an OpenAI LLM instance\n",
    "    #llm = OpenAI(                    # for newer models\n",
    "    llm = ChatOpenAI(                 # for older models\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        max_retries=2,\n",
    "        max_tokens=10  # Slightly increased for safety\n",
    "    )\n",
    "\n",
    "    # Set up the classification chain\n",
    "    classification_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    # Perform Classification\n",
    "    output_string = classification_chain.run(text=input_text).strip()\n",
    "\n",
    "    # Calculate token count\n",
    "    input_count = count_tokens(prompt_template.format(text=input_text))\n",
    "    output_count = count_tokens(output_string)\n",
    "\n",
    "    # Debugging statement (prints the formatted prompt)\n",
    "    #print(f\"Generated Prompt:\\n{prompt_template.format(text=input_text)}\")\n",
    "\n",
    "    return output_string, input_count, output_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompt_templates.json\", \"r\") as file:\n",
    "        templates = json.load(file)\n",
    "\n",
    "# Vizualize templates\n",
    "for name, template in templates.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(template)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to classify a given sentence as either: \n",
      "* 'FUN' - if the sentence describes only the functioning or behavior of a device;\n",
      "* 'STR' - if the sentence describes only the structure or architecture of a device;\n",
      "* 'MIX' - if the sentence describes both the functioning and the structure of a device;\n",
      "* 'OTH' - if the sentence cannot be classified according to any of the previous classes.\n",
      "The output should only contain one of the class labels: FUN, STR, MIX or OTH.\n",
      "Sentence: '{text}' \n",
      "Class: \n",
      "\n",
      "Input Tokens: 142\n",
      "Output Tokens: 1\n",
      "Predicted Class: STR\n"
     ]
    }
   ],
   "source": [
    "# Sample Sentences for Testing\n",
    "input_text = \"Additionally, the stopper 108 is used at the distal end of the wire where the loop is formed to substantially secure the loop closed.\" # MIX\n",
    "input_text = \"Provisional Patent Application number 62/571,193; filed Oct. 11, 2017; and entitled INSECT VACUUM AND TRAP ATTACHMENT SYSTEMS.\" #OTH\n",
    "input_text = \"In some embodiments, the horizontal position of the idler support block 1213 may be adjustable to maintain tension on the chain 1212.\" #FUN\n",
    "input_text = \"If there are no allocated cells to a hub using the previous criterion, the first allocated cell will be the closest cell to that hub.\" #FUN\n",
    "input_text = \"The rigid foam layer 50 is typically selected from the group of polyurethane foams, polyurea foams, and combinations thereof.\" # STR\n",
    "\n",
    "# Select Template\n",
    "template = templates['prompt1']\n",
    "print(template, '\\n')\n",
    "\n",
    "# Test the Classification Function\n",
    "output_string, input_count, output_count = classify_sentence_chatgpt(input_text=input_text, template=template)\n",
    "print(f\"Input Tokens: {input_count}\")\n",
    "print(f\"Output Tokens: {output_count}\")\n",
    "print(f\"Predicted Class: {output_string}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classify Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "test_df = pd.read_excel(\"/home/fantoni/patent-sentence-classification/data/test_agreement.xlsx\")\n",
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 1200/1200 [11:29<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt1 completed.\n"
     ]
    }
   ],
   "source": [
    "# Set the model to use\n",
    "model =  \"gpt-3.5-turbo\"\n",
    "#model =  \"gpt-4o\"\n",
    "\n",
    "# Iterate over templates\n",
    "for templ_name, template in templates.items():\n",
    "    if templ_name in ['prompt_2', 'prompt_4', 'prompt_5']:  # choose and skip specific templates\n",
    "    \n",
    "        # Initialize results dictionary\n",
    "        results = {\n",
    "            'sent_id': [],\n",
    "            'sent': [],\n",
    "            'sent_tag': [],\n",
    "            'predicted_tag': [],\n",
    "            'model_output': [],\n",
    "            'input_count': [],\n",
    "            'output_count': [],\n",
    "            'errors': [],\n",
    "            'elapsed_time_sec': []\n",
    "        }\n",
    "\n",
    "        # Perform Classification\n",
    "        for i, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing Sentences\"):  \n",
    "            start_time = time.time()              \n",
    "            try:\n",
    "                results['sent_id'].append(row['sent_id'])\n",
    "                results['sent'].append(row['sent'])\n",
    "                results['sent_tag'].append(row['sent_tag'])\n",
    "\n",
    "                # Get classification\n",
    "                output_string, input_count, output_count = classify_sentence_chatgpt(input_text=row['sent'], template=template, model=model)\n",
    "\n",
    "                # Validate classification output\n",
    "                if output_string not in [\"FUN\", \"STR\", \"MIX\", \"OTH\"]:\n",
    "                    raise ValueError(f\"Invalid Classification Tag.\")\n",
    "\n",
    "                # Append Results \n",
    "                results['predicted_tag'].append(output_string)\n",
    "                results['model_output'].append(output_string)\n",
    "                results['errors'].append(None)  # No error occurred\n",
    "                results['input_count'].append(input_count)  # Append input token count when successful\n",
    "                results['output_count'].append(output_count)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Handle any errors that occur during processing\n",
    "                print(f\"Error in sentence {row['sent_id']}: {e}. Skipping...\")\n",
    "                results['predicted_tag'].append(\"ERROR\")\n",
    "                results['model_output'].append(output_string)\n",
    "                results['input_count'].append(\"ERROR\") \n",
    "                results['output_count'].append(\"ERROR\") \n",
    "                results['errors'].append(str(e))\n",
    "            \n",
    "            finally:\n",
    "                # Tracking how long it took to process the sentence\n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time-start_time\n",
    "                results['elapsed_time_sec'].append(f\"{elapsed_time}\")\n",
    "\n",
    "        # Convert results to DataFrame and Save\n",
    "        result_df = pd.DataFrame(results)\n",
    "        result_df.to_excel(f'/home/fantoni/patent-sentence-classification/results/prompting/{model}_{templ_name}_new.xlsx', index = False)\n",
    "        print(f\"{templ_name} completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
