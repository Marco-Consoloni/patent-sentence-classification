{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain Import\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Finetuned Model Import\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from src.model import PatentSentenceClassifier\n",
    "\n",
    "# Load OpenaAI API key\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIX Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Defintion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to divide a given sentence into sub-sentences.\n",
      "Insert periods to divide the sentence into meaningful sub-sentences. \n",
      "Maintain the original words without any changes. \n",
      "Do not use pronouns; instead, repeat the original subjects as needed.\n",
      "\n",
      "Input Format: A single sentence.\n",
      "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
      "\n",
      "Input: \"{text}\"\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Prompt Definition\n",
    "task = \"\"\"Your task is to divide a given sentence into sub-sentences.\n",
    "Insert periods to divide the sentence into meaningful sub-sentences. \n",
    "Maintain the original words without any changes. \n",
    "Do not use pronouns; instead, repeat the original subjects as needed.\n",
    "\n",
    "Input Format: A single sentence.\n",
    "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
    "\"\"\"\n",
    "output_format = \"Input: \\\"{text}\\\"\\nOutput:\"\n",
    "splitting_prompt = '\\n'.join([task, output_format])\n",
    "print(splitting_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def split_sentence_chatgpt(input_text, prompt, model=\"gpt-4o\", temperature=0, top_p=1):\n",
    "    \n",
    "    # Define a prompt template for classification\n",
    "    prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "    # Create an OpenAI LLM instance\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_retries=1,\n",
    "        max_tokens=1000 \n",
    "    )\n",
    "\n",
    "    # Create a runnable sequence\n",
    "    split_sentence_chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    # Format prompt\n",
    "    formatted_prompt = prompt_template.format(text=input_text)\n",
    "    #print(f\"Generated Prompt:\\n{formatted_prompt}\") # Debugging statement\n",
    "\n",
    "    # Perform Classification\n",
    "    output_string = split_sentence_chain.invoke({\"text\": input_text}).strip()\n",
    "\n",
    "    # Calculate token count\n",
    "    input_count = count_tokens(formatted_prompt)\n",
    "    output_count = count_tokens(output_string)\n",
    "\n",
    "    print(f\"Using: model = '{model}'; temperature = {temperature}; top_p = {top_p}\")\n",
    "\n",
    "    return output_string, formatted_prompt, input_count, output_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Sentences from test set\n",
    "test_df = pd.read_excel(\"/home/fantoni/patent-sentence-classification/data/1200_agreement_All.xlsx\")\n",
    "test_df = test_df.query(\"agreement==True & sent_tag_mc == 'MIX'\")\n",
    "input_text = test_df['sent'].iloc[3] # select by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n",
      "Output is in list format.\n"
     ]
    }
   ],
   "source": [
    "# Select Model\n",
    "chatgpt_model ='gpt-3.5-turbo'\n",
    "\n",
    "# Perfrom Sentence Splitting\n",
    "output_string, formatted_prompt, input_count, output_count = split_sentence_chatgpt(input_text, splitting_prompt, chatgpt_model)\n",
    "\n",
    "# Validate Output Format\n",
    "if not output_string:  \n",
    "    raise ValueError(f\"Output is empty.\")\n",
    "try:\n",
    "    output_string = ast.literal_eval(output_string.replace('\\n', ''))\n",
    "    print(f\"Output is in list format.\") \n",
    "except (SyntaxError, ValueError) as e:\n",
    "    raise ValueError(f\"Output not in list format: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generated_sent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rouge1_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge3_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge5_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge7_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge9_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rougeL_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "output_string",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "input_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2497bce5-8073-40d8-9f2b-d240ecc6e11b",
       "rows": [
        [
         "0",
         "As shown in figures 2-5, the treatment assembly 20 of the medical device 16 may include a carrier assembly 36 that supports the electrode array 28 thereon.",
         "Your task is to divide a given sentence into sub-sentences.\nInsert periods to divide the sentence into meaningful sub-sentences. \nMaintain the original words without any changes. \nDo not use pronouns; instead, repeat the original subjects as needed.\n\nInput Format: A single sentence.\nOutput Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n\nInput: \"As shown in figures 2-5, the treatment assembly 20 of the medical device 16 may include a carrier assembly 36 that supports the electrode array 28 thereon.\"\nOutput:",
         "As shown in figures 2-5",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0",
         "['As shown in figures 2-5', 'the treatment assembly 20 of the medical device 16 may include a carrier assembly 36', 'that supports the electrode array 28 thereon.']",
         "143",
         "41"
        ],
        [
         "1",
         "As shown in figures 2-5, the treatment assembly 20 of the medical device 16 may include a carrier assembly 36 that supports the electrode array 28 thereon.",
         "Your task is to divide a given sentence into sub-sentences.\nInsert periods to divide the sentence into meaningful sub-sentences. \nMaintain the original words without any changes. \nDo not use pronouns; instead, repeat the original subjects as needed.\n\nInput Format: A single sentence.\nOutput Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n\nInput: \"As shown in figures 2-5, the treatment assembly 20 of the medical device 16 may include a carrier assembly 36 that supports the electrode array 28 thereon.\"\nOutput:",
         "the treatment assembly 20 of the medical device 16 may include a carrier assembly 36",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "['As shown in figures 2-5', 'the treatment assembly 20 of the medical device 16 may include a carrier assembly 36', 'that supports the electrode array 28 thereon.']",
         "143",
         "41"
        ],
        [
         "2",
         "As shown in figures 2-5, the treatment assembly 20 of the medical device 16 may include a carrier assembly 36 that supports the electrode array 28 thereon.",
         "Your task is to divide a given sentence into sub-sentences.\nInsert periods to divide the sentence into meaningful sub-sentences. \nMaintain the original words without any changes. \nDo not use pronouns; instead, repeat the original subjects as needed.\n\nInput Format: A single sentence.\nOutput Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n\nInput: \"As shown in figures 2-5, the treatment assembly 20 of the medical device 16 may include a carrier assembly 36 that supports the electrode array 28 thereon.\"\nOutput:",
         "that supports the electrode array 28 thereon.",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "0.0",
         "1.0",
         "['As shown in figures 2-5', 'the treatment assembly 20 of the medical device 16 may include a carrier assembly 36', 'that supports the electrode array 28 thereon.']",
         "143",
         "41"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_sent</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge3_precision</th>\n",
       "      <th>rouge5_precision</th>\n",
       "      <th>rouge7_precision</th>\n",
       "      <th>rouge9_precision</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>output_string</th>\n",
       "      <th>input_count</th>\n",
       "      <th>output_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As shown in figures 2-5, the treatment assembl...</td>\n",
       "      <td>Your task is to divide a given sentence into s...</td>\n",
       "      <td>As shown in figures 2-5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[As shown in figures 2-5, the treatment assemb...</td>\n",
       "      <td>143</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As shown in figures 2-5, the treatment assembl...</td>\n",
       "      <td>Your task is to divide a given sentence into s...</td>\n",
       "      <td>the treatment assembly 20 of the medical devic...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[As shown in figures 2-5, the treatment assemb...</td>\n",
       "      <td>143</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As shown in figures 2-5, the treatment assembl...</td>\n",
       "      <td>Your task is to divide a given sentence into s...</td>\n",
       "      <td>that supports the electrode array 28 thereon.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[As shown in figures 2-5, the treatment assemb...</td>\n",
       "      <td>143</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  As shown in figures 2-5, the treatment assembl...   \n",
       "1  As shown in figures 2-5, the treatment assembl...   \n",
       "2  As shown in figures 2-5, the treatment assembl...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Your task is to divide a given sentence into s...   \n",
       "1  Your task is to divide a given sentence into s...   \n",
       "2  Your task is to divide a given sentence into s...   \n",
       "\n",
       "                                      generated_sent  rouge1_precision  \\\n",
       "0                            As shown in figures 2-5               1.0   \n",
       "1  the treatment assembly 20 of the medical devic...               1.0   \n",
       "2      that supports the electrode array 28 thereon.               1.0   \n",
       "\n",
       "   rouge3_precision  rouge5_precision  rouge7_precision  rouge9_precision  \\\n",
       "0               1.0               1.0               0.0               0.0   \n",
       "1               1.0               1.0               1.0               1.0   \n",
       "2               1.0               1.0               1.0               0.0   \n",
       "\n",
       "   rougeL_precision                                      output_string  \\\n",
       "0               1.0  [As shown in figures 2-5, the treatment assemb...   \n",
       "1               1.0  [As shown in figures 2-5, the treatment assemb...   \n",
       "2               1.0  [As shown in figures 2-5, the treatment assemb...   \n",
       "\n",
       "   input_count  output_count  \n",
       "0          143            41  \n",
       "1          143            41  \n",
       "2          143            41  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ROUGE scorer\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "results = []\n",
    "\n",
    "for generated_sent in output_string:\n",
    "    score = rouge(generated_sent, input_text)\n",
    "\n",
    "    results.append({\n",
    "        'input_text': input_text,\n",
    "        'prompt': formatted_prompt,\n",
    "        'generated_sent': generated_sent,\n",
    "        #'pred_sent_class': pre_class,\n",
    "        #'probs': probs,\n",
    "        'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "        'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "        'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "        'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "        'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "        'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "        'output_string': output_string,\n",
    "        'input_count': input_count,\n",
    "        'output_count': output_count,\n",
    "        #'errors': None,\n",
    "        #'elapsed_time_sec': time.time() - start_time()\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Base Tokenizer loaded succesfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at anferico/bert-for-patents and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model loaded succesfully.\n",
      "\n",
      "Finetuned model loaded succesfully. Using: 'bert-for-patents_train_10_7'\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set path to checkpoint\n",
    "checkpoint_name = 'bert-large-uncased_train_10_7'; model_name = \"bert-large-uncased\"\n",
    "checkpoint_name = 'bert-for-patents_train_10_7'; model_name = \"anferico/bert-for-patents\" \n",
    "checkpoint_path = f\"/home/fantoni/patent-sentence-classification/models/finetuning/{checkpoint_name}.ckpt\"\n",
    "\n",
    "# Load Base Tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "print('\\nBase Tokenizer loaded succesfully.')\n",
    "\n",
    "# Load Base Model\n",
    "base_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "print('\\nBase model loaded succesfully.')\n",
    "\n",
    "# Load Finetuned Model\n",
    "model = PatentSentenceClassifier.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    model=base_model,\n",
    "    tokenizer=bert_tokenizer)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"\\nFinetuned model loaded succesfully. Using: '{checkpoint_name}'\")\n",
    "\n",
    "# Define Finetuned Tokenizer\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(model, input_text, device='cpu'):\n",
    "    \n",
    "    # Tokenize input\n",
    "    tokenizer = model.tokenizer  # Assuming tokenizer is part of the model\n",
    "    inputs = tokenizer(input_text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Move input to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Define label mapping\n",
    "    int_to_label = {0: 'FUN', 1: 'STR', 2: 'MIX', 3: 'OTH'}\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0]\n",
    "        pred_idx = torch.argmax(probs).item()\n",
    "        pred_class = int_to_label[pred_idx]\n",
    "\n",
    "    return pred_class, [round(p, 2) for p in probs.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 1/1 [00:07<00:00,  7.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize ROUGE scorer\n",
    "# reference: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "# Import Sentences\n",
    "test_df = pd.read_excel(\"/home/fantoni/patent-sentence-classification/data/1200_agreement_All.xlsx\")\n",
    "test_df = test_df.query(\"agreement==True & sent_tag_mc == 'MIX'\")\n",
    "test_df = test_df.head(1) \n",
    "\n",
    "# Select Models\n",
    "chatgpt_model ='gpt-3.5-turbo'\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing Sentences\"):  \n",
    "    start_time = time.time()              \n",
    "    try:\n",
    "        original_sent = row['sent']\n",
    "        \n",
    "        # Split Sentence \n",
    "        output_string, formatted_prompt, input_count, output_count = split_sentence_chatgpt(original_sent, splitting_prompt, chatgpt_model)\n",
    "\n",
    "        # Validate Output Format\n",
    "        if not output_string:  \n",
    "            raise ValueError(f\"Output is empty.\")\n",
    "        try:\n",
    "            # Convert string to list\n",
    "            output_string = ast.literal_eval(output_string)  \n",
    "            #print(f\"Output is in list format.\") \n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            raise ValueError(f\"Output not in list format: {e}\")\n",
    "\n",
    "        # Iterate over the generated sentences\n",
    "        for generated_sent in output_string:\n",
    "\n",
    "            # Classify Sub-Sentences\n",
    "            pre_class, probs = classify_text(model, generated_sent, device)\n",
    "\n",
    "            # Compute ROUGE Score\n",
    "            score = rouge(generated_sent, original_sent)\n",
    "            \n",
    "            # Append Results\n",
    "            results.append({\n",
    "                'sent_id': row['sent_id'],\n",
    "                'original_sent_class': row['sent_tag_mc'],\n",
    "                'original_sent': original_sent,\n",
    "                'prompt': formatted_prompt,\n",
    "                'generated_sent': generated_sent,\n",
    "                'pred_sent_class': pre_class,\n",
    "                'probs': probs,\n",
    "                'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "                'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "                'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "                'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "                'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "                'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "                'output_string': output_string,\n",
    "                'input_count': input_count,\n",
    "                'output_count': output_count,\n",
    "                'errors': None,\n",
    "                'elapsed_time_sec': time.time() - start_time\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['sent_id']}: {str(e)}\")\n",
    "        results.append({\n",
    "            'sent_id': row['sent_id'],\n",
    "            'original_sent_class': row['sent_tag_mc'],\n",
    "            'original_sent': original_sent,\n",
    "            'prompt': formatted_prompt,\n",
    "            'generated_sent': None,\n",
    "            'pred_sent_class': None,\n",
    "            'probs': None,\n",
    "            'rouge1_precision': None,\n",
    "            'rouge3_precision': None,\n",
    "            'rouge5_precision': None,\n",
    "            'rouge7_precision': None,\n",
    "            'rouge9_precision': None,\n",
    "            'rougeL_precision': None,\n",
    "            'output_string': output_string,\n",
    "            'input_count': None,\n",
    "            'output_count': None,\n",
    "            'errors': str(e),\n",
    "            'elapsed_time_sec': time.time() - start_time\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "\n",
    "# Save results to Excel\n",
    "results_df.to_excel(\"/home/fantoni/patent-sentence-classification/results/mix_disambiguation/mix_disambiguation.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim Rephrasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A method of administering a wagering game, comprising:\n",
      "accepting an ante wager from a player by receiving a chip on a surface of a table;\n",
      "dealing a partial hand to the player from a set of randomly ordered cards and permitting the player to view the partial hand;\n",
      "after permitting the player to view the at least one card and while prohibiting the player from folding, accepting from the player an initial election to check after offering the player initial options selected from the group consisting of check or place a play wager of a first value;\n",
      "dealing at least one other card from the set available to the player to form a complete hand and permitting the player to view the at least one other card;\n",
      "after permitting the player to view the at least one other card, accepting from the player a subsequent election to place a play wager of a second, lesser value by receiving another chip on the surface of the table after offering the player subsequent options selected from the group consisting of fold or place the play wager of the second value or less; and\n",
      "resolving the ante wager and the play wager.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sent_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "section",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sent",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "46a95de1-245e-48ee-ba38-c77bb379807f",
       "rows": [
        [
         "0",
         "1",
         "description",
         "Description"
        ],
        [
         "1",
         "2",
         "description",
         "CROSS-REFERENCE TO RELATED APPLICATIONS"
        ],
        [
         "2",
         "3",
         "description",
         "[0001]"
        ],
        [
         "3",
         "4",
         "description",
         "This application is a continuation of U.S. patent application Ser."
        ],
        [
         "4",
         "5",
         "description",
         "number 13/549,969, filed Jul."
        ],
        [
         "5",
         "6",
         "description",
         "16, 2012, pending, which is a continuation of U.S. patent application Ser."
        ],
        [
         "6",
         "7",
         "description",
         "number 11/156,352, filed Jun."
        ],
        [
         "7",
         "8",
         "description",
         "17, 2005, now abandoned."
        ],
        [
         "8",
         "9",
         "description",
         "This application is also related to U.S. patent application Ser."
        ],
        [
         "9",
         "10",
         "description",
         "number 13/455,742, filed Apr."
        ],
        [
         "10",
         "11",
         "description",
         "25, 2012, pending, which application is a divisional of the aforementioned U.S. patent application Ser."
        ],
        [
         "11",
         "12",
         "description",
         "number 11/156,352."
        ],
        [
         "12",
         "13",
         "description",
         "This application is also related to U.S. patent application Ser."
        ],
        [
         "13",
         "14",
         "description",
         "number 12/490,233, filed Jun."
        ],
        [
         "14",
         "15",
         "description",
         "23, 2009, pending."
        ],
        [
         "15",
         "16",
         "description",
         "The disclosure of each of the foregoing applications is hereby incorporated herein by this reference in its entirety."
        ],
        [
         "16",
         "17",
         "description",
         "This application is also related to U.S. patent application Ser."
        ],
        [
         "17",
         "18",
         "description",
         "number 13/631,816, filed Sep. 28, 2012, pending, which is a continuation-in-part of this application."
        ],
        [
         "18",
         "19",
         "description",
         "FIELD"
        ],
        [
         "19",
         "20",
         "description",
         "[0002]"
        ],
        [
         "20",
         "21",
         "description",
         "The present invention relates to wagering games, casino table wagering games, casino table playing card wagering games, and variants of casino table wagering games that use poker ranks in determining outcomes."
        ],
        [
         "21",
         "22",
         "description",
         "BACKGROUND"
        ],
        [
         "22",
         "23",
         "description",
         "[0003]"
        ],
        [
         "23",
         "24",
         "description",
         "Many different wagering games presently exist for use in both home and casino environments."
        ],
        [
         "24",
         "25",
         "description",
         "Such games should necessarily be exciting, uncomplicated and easy to learn so as to avoid frustrating the players."
        ],
        [
         "25",
         "26",
         "description",
         "Poker games in particular have gained widespread popularity because of their established ranking of hands and well-known rules."
        ],
        [
         "26",
         "27",
         "description",
         "Furthermore, the games usually involve numerous wagering opportunities for the players, thus increasing player participation and excitement."
        ],
        [
         "27",
         "28",
         "description",
         "Lastly, the games move fairly quickly to maintain player interest."
        ],
        [
         "28",
         "29",
         "description",
         "All of these factors have created games that are widely accepted and widely known."
        ],
        [
         "29",
         "30",
         "description",
         "[0004]"
        ],
        [
         "30",
         "31",
         "description",
         "Variations in wagering structures can also increase the excitement and acceptance of such wagering games."
        ],
        [
         "31",
         "32",
         "description",
         "U.S. Pat."
        ],
        [
         "32",
         "33",
         "description",
         "number 5,417,430 to Breeding discloses a poker game with an altered wagering scheme, thus allowing the player the opportunity to compete for additional and larger prizes or payouts."
        ],
        [
         "33",
         "34",
         "description",
         "[0005]"
        ],
        [
         "34",
         "35",
         "description",
         "Other variations can be made to standard games to allow more player opportunity and involvement."
        ],
        [
         "35",
         "36",
         "description",
         "U.S. Pat."
        ],
        [
         "36",
         "37",
         "description",
         "number 5,098,107 to Boylan and others discloses a game wherein additional game symbols are added to increase wagering opportunities."
        ],
        [
         "37",
         "38",
         "description",
         "This allows the player the opportunity to place several wagers on different portions of the game while the game is being played."
        ],
        [
         "38",
         "39",
         "description",
         "[0006]"
        ],
        [
         "39",
         "40",
         "description",
         "Many variations in the play of poker-type games have been introduced to increase the excitement and interest in the play of both table and video versions of poker."
        ],
        [
         "40",
         "41",
         "description",
         "[0007]"
        ],
        [
         "41",
         "42",
         "description",
         "Many of the poker variants mentioned above are played against a dealer hand."
        ],
        [
         "42",
         "43",
         "description",
         "In more traditional forms of poker, players play against other players, and a highest ranking hand wins the round."
        ],
        [
         "43",
         "44",
         "description",
         "For example, Texas Hold 'Em is a game in which players compete against other players to make a best five-card hand from seven available cards."
        ],
        [
         "44",
         "45",
         "description",
         "After the first round of wagering, each player is dealt two hole cards."
        ],
        [
         "45",
         "46",
         "description",
         "Five community cards are dealt face down on the table."
        ],
        [
         "46",
         "47",
         "description",
         "After viewing the hole cards, each player is given the opportunity to make an additional wager."
        ],
        [
         "47",
         "48",
         "description",
         "The additional wager must at least match the opening bet for the round or the player folds."
        ],
        [
         "48",
         "49",
         "description",
         "The dealer then reveals the first three community cards."
        ],
        [
         "49",
         "50",
         "description",
         "Another round of betting takes place."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 719
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>section</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>description</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>description</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>description</td>\n",
       "      <td>[0001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>description</td>\n",
       "      <td>This application is a continuation of U.S. pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>description</td>\n",
       "      <td>number 13/549,969, filed Jul.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>715</td>\n",
       "      <td>claims</td>\n",
       "      <td>The method of claim 15, wherein the at least o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>716</td>\n",
       "      <td>claims</td>\n",
       "      <td>The method of claim 15, wherein the at least o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>717</td>\n",
       "      <td>claims</td>\n",
       "      <td>The method of claim 18, wherein the at least o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>718</td>\n",
       "      <td>claims</td>\n",
       "      <td>The method of claim 19, wherein the at least o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>719</td>\n",
       "      <td>first_claim</td>\n",
       "      <td>1. A method of administering a wagering game, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sent_id      section                                               sent\n",
       "0          1  description                                        Description\n",
       "1          2  description            CROSS-REFERENCE TO RELATED APPLICATIONS\n",
       "2          3  description                                             [0001]\n",
       "3          4  description  This application is a continuation of U.S. pat...\n",
       "4          5  description                      number 13/549,969, filed Jul.\n",
       "..       ...          ...                                                ...\n",
       "714      715       claims  The method of claim 15, wherein the at least o...\n",
       "715      716       claims  The method of claim 15, wherein the at least o...\n",
       "716      717       claims  The method of claim 18, wherein the at least o...\n",
       "717      718       claims  The method of claim 19, wherein the at least o...\n",
       "718      719  first_claim  1. A method of administering a wagering game, ...\n",
       "\n",
       "[719 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Select patent\n",
    "#patent_id = 'US8695121B2'; IPC = 'A42B3' \n",
    "#patent_id = 'US11133720B2'; IPC = 'H02K3' \n",
    "#patent_id = 'US9468782B2'; IPC = 'A62B23' \n",
    "#patent_id = 'US11673469B2'; IPC = 'B60K37'\n",
    "patent_id = 'US20200074811A1'; IPC = 'G07F17'\n",
    "\n",
    "df = pd.read_excel(f\"/home/fantoni/patent-sentence-classification/data/patents/{patent_id}_{IPC}.xlsx\")\n",
    "input_text = df[df['section'] == 'first_claim']['sent'].iloc[0] # get first claim\n",
    "print(input_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Select patent Pavanello\n",
    "#IPC = 'F16D65-12'; patent_id = \"WO-2019021161-A1\" ; input_text = \"\"\"1. Method for making a brake disc, comprising the following operating steps: a) arranging a brake disc, comprising a braking band (2) provided with two opposed braking surfaces (2a, 2b) , each of which defines at least partially one of two main sides of the disc, the braking band being made of aluminium or aluminium alloy or being made of grey cast iron or steel; b) depositing on the disc a layer of chromium carbide (Cr3C2) and nickel-chromium (NiCr) in particle form by HVOF (High Velocity Oxygen Fuel) technique or by HVAF (High Velocity Air Fuel) technique or by KM (Kinetic Metallization) technique, forming a base protective coating (30) covering at least one of the two braking surfaces of the braking band in direct contact therewith; and c) depositing on said base protective coating (30) a material in particle form consisting of tungsten carbide (WC) , iron (Fe), chromium (Cr) and aluminium (Al) by HVOF (High Velocity Oxygen Fuel) technique or by HVAF (High Velocity Air Fuel) technique or by KM (Kinetic Metallization) technique, forming a surface protective coating (3), consisting of tungsten carbide (WC) and iron (Fe), chromium (Cr) and aluminium (Al) and covering at least one of the two braking surfaces of the braking band.\"\"\"\n",
    "#IPC = 'F16D55-288'; patent_id = \"WO-2019243958-A1\"; input_text = \"\"\"1. A spring (22) for friction pads (1 1 ) associable with a caliper (2) of a disc brake (1 ) for elastically biasing the friction pads (1 1 ) away from a brake disc (3) of the disc brake (1 ), said spring (22) comprising a traverse elongated plate (25) folded so as to form a central stretch (26) and two opposite transverse stretches (27), extending from the central stretch (26) in two opposite transverse directions with respect to a longitudinal median plane (28) of the spring (22), said opposite transverse stretches (27) each forming a supporting stretch (29), a resting stretch (30) and a wing stretch (31 ) extending between the supporting stretch (29) and the resting stretch (30), wherein the supporting stretches (29) border on the central stretch (26) and oriented so that both supporting stretches (29) lie on a same supporting plane (32) transverse, possibly orthogonal, to the longitudinal median plane (28), wherein the wing stretch (31 ) borders on the respective supporting stretch (29) and comprises: - an ascending wing stretch (33) extending from the supporting stretch (29) away from the supporting plane (32) towards an upper side (34) of the spring (22) and away from the longitudinal median plane (28) to an upper apical point (35), - a descending wing stretch (36) extended from the upper apical point (35) further away from the longitudinal median plane (28) and towards a lower side (37) of the spring (22) to a folding line (38) which connects the wing stretch (31 ) to the resting stretch (30), wherein the spring (22) further comprises one or more fixing stretches (39) connected to the central stretch (26) and forming at least two opposite fixing stretches (40) for an elastic snap fixing to corresponding fixing seats (41 ) of the caliper (2), and wherein the resting stretch (30) forms: - a plate-shaped contact portion (44) for a free support, with possibility of sliding, against a corresponding contact surface (45) of the friction pad (1 1 ), - a plate-shaped intermediate portion (46) extending between the wing stretch (31 ) and the contact portion (44), wherein, with the spring (22) undeformed, the intermediate portion (46) extends transversely with respect to the supporting plane (32) towards the lower side (37) of the spring (22) and the contact portion (44) extends, starting from a folding edge (48) formed between the contact portion (44) and the intermediate portion (46), so as to diverge with respect to the supporting plane (32) and towards the longitudinal median plane (28).\"\"\"\n",
    "#IPC = 'B6078-1706'; patent_id = \"WO-2020058819-A1\"; input_text = \"\"\"1. A braking system (4) for motorcycles comprising - a first manual actuator device (8), operable by means of a lever and / or a pedal, selectively connectable to at least a first braking device (12) placed on a front axle (16) of the vehicle, and/or at least a second braking device (20) placed on said front axle (16) or on a rear axle (22) of the motorcycle, each braking device (4) acting on a relative brake disc or drum (14), - the first manual actuator device (8) being provided with a hydraulic supply circuit (24) that can be selectively connected to a hydraulic input circuit (28) of at least one of said braking devices (12,20) by means of a control valve (32), said control valve (32) being positioned in an operating position, in which it hydraulically disconnects the first manual actuator device (8) from the braking devices (12,20), and in an electrical fault position, in which it hydraulically connects the first manual actuator device (8) with at least one of said braking devices (12,20), at least one electro-hydraulic automatic actuator device (36) fluidly connectable to the hydraulic input circuit (28) of at least one of said braking devices (12, 20) for the respective hydraulic actuation thereof, at least one electromechanical automatic actuator device (40) associated with at least one of said braking devices (12, 20) not provided with a hydraulic input circuit (28), - the electro-hydraulic automatic actuator devices (36) being associated with the front axle (16) and the electromechanical automatic actuator devices (40) being associated with the rear axle (22) of the motorcycle or vice versa, - a single control unit (44) operatively connected to the control valve (32), to the at least one electro-hydraulic automatic actuator device (36), to the at least one electromechanical automatic actuator device (40) and to the first manual actuator device (8) so as to operate said electro-hydraulic (36) and electromechanical (40) automatic actuator devices and said control valve (32) according to the position or configuration of the first manual actuator device (8) and/or according to the dynamics of the motorcycle.\"\"\"\n",
    "IPC = 'B6078-261'; patent_id = \"WO-2022144719-A1\"; input_text = \"\"\"1. A braking system (4) for a motorcycle (8) comprising: - at least one first brake (12) associated with a front wheel of said motorcycle (8), - at least one first electro-hydraulic or electromechanical actuator (16), operatively connected to said first brake (12), - at least one first manual actuation command (20), associated with and corresponding to said at least one first brake (12), to send a braking request from a user, - at least a second brake (24) associated with a rear wheel of said motorcycle (8), - at least a second electro-hydraulic or electromechanical actuator (28) operatively connected to said second brake (24), - at least a second manual actuation command (32), associated with and corresponding to said at least one second brake (24), to send a braking request from a user, - a control unit (36) operatively connected to the first manual actuation command (20), the second manual actuation command (32) and said first and second electro- hydraulic or electro-mechanical actuators (16,28), - wherein said control unit (36) is programmed to: - receive a braking request from the user following actuation of at least one of said manual actuation commands (20,32), - interpreting the braking request as a function of which or how many actuation commands have actually been actuated, and/or the intensity of such actuation given by a stroke and/or actuation force or pressure of the corresponding manual actuation command (20,32), - activating at least one of said electro-hydraulic or electro-mechanical actuators (16,28), irrespective of the effective actuation of the corresponding manual actuation command (20,32), so as to obtain a deceleration of the motorcycle (8) as a function of said braking request.\"\"\"\n",
    "#IPC = 'C08J5-0405'; patent_id = \"WO-2017216367-A1\"; input_text = \"\"\"1. A process to make a flexible composite material comprising flexible ceramic nanofibers and a polymer, the process of making flexible ceramic nanofibers comprising the steps of: a. Preparing a ceramic fibers' precursor solution, the precursor solution comprising (i) a dissolved metal's precursor for ceramic selected from the group consisting of metallic ions and metal containing polymer, where the metals are preferably selected from the group consisting of Si4+, Zr4+, ΤΊ4+, Y3+, Al3+, Zn2+, Mg2+, Pb4+ , Ni2+, Sr2+, Ca2+, La3+ ; (ii) a polymer to increase the precursor solution's viscosity, with the solid content of the precursor solution (polymer plus precursor) being above 5% by weight, preferably 15% by weight, in order to obtain the required deposition, and (iii) solvent capable of providing the precursor solution giving a sufficiently high evaporation rate; b. Allowing the dissolved metal precursors for ceramic to form a final metal oxide also known as ceramic; c. Maintaining the precursor solution's viscosity between 0.01 and 1000 Pascal- second (Pa-s), preferably between 0.01 and 5000 Pascal-second (Pa-s), at a shear rate of 0,01 to 1 s\"1, preferably 0.1 s\"1, in order to spin usable fibers; d. Spinning the precursor solution by using a spinning process selected from the group consisting of for example forcespinning, electrospinning and blowspinning wherein the spinning parameters are tunable so that the spinning step can result in polymeric fibers and with the spinning parameters being adaptable to each precursor solution; e. Annealing the polymeric fibers obtained from the spinning process, the polymeric fibers comprising the metals precursors for ceramic, until all the organic content is burned out and the metallic ion oxidizes to form a ceramic; f. Tuning and calibrating annealing parameters, the annealing parameters comprising heating and cooling rates, annealing temperature and dwell time consistent with preferably a trapezium shaped thermal profile so a crystallinity comprising a crystal size of 1 to 100 nm and a smoothness of 0.05 to 5 nm of Rq of the resulting 20 to 10000 nm thick fibers is obtained, the annealing parameters being distinct and specific with respect to each material composition; g. Setting the annealing temperature above the ceramic fiber's crystallization point resulting in the formation of ceramic material; and h. Setting a dwell time from 0 to 5 hours or even more.\"\"\"\n",
    "#IPC = 'G06F30-30'; patent_id = \"US-10733341-B1\"; input_text = \"\"\"1. A computer-implemented method comprising: retrieving, by a network node in a plurality of distributed network nodes, code differentials between successive iterations of an integrated circuit design in a hardware description language; iteratively generating, by the network node, a first plurality of digital blocks for a first chain in a first direction within a two-dimensional distributed digital ledger hosted by the plurality of distributed network nodes, the first plurality of digital blocks containing hashes of corresponding code differentials generated by the network node using a first hashing protocol associated with a first level of security; retrieving, by the network node, a plurality of simulation data records generated through successive simulation operations on the integrated circuit design; iteratively generating, by the network node, a second plurality of digital blocks for a second chain in a second direction within the two-dimensional distributed ledger, the second plurality of digital blocks containing hashes of corresponding simulation data records generated by the network node using a second hashing protocol using a second level of security, such that the second chain is cryptographically separate from the first chain; associating, by the network node, the first plurality of digital blocks and the second plurality of digital blocks to a physically unclonable function in an integrated circuit fabricated from the integrated circuit design; in response to the network node receiving a first query containing the physically unclonable function from a first user with first level security credentials: displaying, by the network node, the code differentials of the integrated circuit design; and in response to the network node receiving a second query containing the physically unclonable function from a second user with second level security credentials: displaying, by the network node, the plurality of simulation data records of the integrated circuit design.\"\"\"\n",
    "#IPC = 'B65G1-023'; patent_id = \"IT-201900008253-A1\"; input_text = \"\"\"1. A system (10) comprising: - a roller box (15) which includes: ● two parallel sides (25), ● at least one horizontal shelf (R) defined by a plurality of idle rollers (20) placed side by side along a side-by-side direction (A) in which each roller (20) is supported at opposite ends by a respective side (25) received in a seat through made in the respective side (25), at least one first end (30) of the ends of each roller (20) presenting a prismatic seat (70), in which the first ends (30) of the rollers (20) all protrude from the same side (25), and ● a connection assembly configured to pivotally connect each seat to the respective end of a roller (20), the system (10), furthermore, comprising: - a drive device (P) which comprises: or a frame (T), either a horizontal bar (65) sliding vertically on the frame (T), or a plurality of mandrels (M) rotatably associated with the bar (65) with respect to a horizontal axis of revolution, in which each mandrel (M) can be inserted in a seat prismatic (70) of a respective roller (20), in which each spindle (M) comprises: ● a prismatic gripping head (75) placed at the free end of a shaft (80), and ● a bushing (85) equipped with an external fluted jacket inserted by coaxial interference on the end opposite the free end of the shaft (80), characterized in that said bushing (85) is made of a rigid material and the shaft (80) is flexible.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Sentence Splitting and Classification\n",
    "\n",
    "different results ChatGPT and API ChatGPT : https://community.openai.com/t/different-results-same-prompt-on-openai-api-vs-chatgpt/1062995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c45fb7e8-d705-4e91-8e44-4bec7e73c8c8",
       "rows": [
        [
         "0",
         "1",
         "1. A braking system (4) for a motorcycle (8) comprising: - at least one first brake (12) associated with a front wheel of said motorcycle (8), - at least one first electro-hydraulic or electromechanical actuator (16), operatively connected to said first brake (12), - at least one first manual actuation command (20), associated with and corresponding to said at least one first brake (12), to send a braking request from a user, - at least a second brake (24) associated with a rear wheel of said motorcycle (8), - at least a second electro-hydraulic or electromechanical actuator (28) operatively connected to said second brake (24), - at least a second manual actuation command (32), associated with and corresponding to said at least one second brake (24), to send a braking request from a user, - a control unit (36) operatively connected to the first manual actuation command (20), the second manual actuation command (32) and said first and second electro- hydraulic or electro-mechanical actuators (16,28), - wherein said control unit (36) is programmed to: - receive a braking request from the user following actuation of at least one of said manual actuation commands (20,32), - interpreting the braking request as a function of which or how many actuation commands have actually been actuated, and/or the intensity of such actuation given by a stroke and/or actuation force or pressure of the corresponding manual actuation command (20,32), - activating at least one of said electro-hydraulic or electro-mechanical actuators (16,28), irrespective of the effective actuation of the corresponding manual actuation command (20,32), so as to obtain a deceleration of the motorcycle (8) as a function of said braking request."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1. A braking system (4) for a motorcycle (8) c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text\n",
       "0        1  1. A braking system (4) for a motorcycle (8) c..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Chunking approach: divide first claim into chunks using simple regex\n",
    "#chunks = [sent.replace('\\n', ' ') + '.' for sent in re.split(r'(?:;\\sand\\n)', input_text)]\n",
    "#df = pd.DataFrame({'text_id': range(1, len(chunks)+1), 'text': chunks})\n",
    "\n",
    "# 2. As-Is approach: use first claim as is\n",
    "df = pd.DataFrame({'text_id': [1], 'text': input_text})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-4o'; temperature = 0; top_p = 1\n",
      "Output is in list format.\n",
      "Found MIX sentence, retry splitting and classification ...\n",
      "Using: model = 'gpt-4o'; temperature = 0; top_p = 1\n",
      "Output is in list format.\n",
      "Found MIX sentence, retry splitting and classification ...\n",
      "Using: model = 'gpt-4o'; temperature = 0; top_p = 1\n",
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 1/1 [00:30<00:00, 30.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize ROUGE scorer with various n-gram options\n",
    "# reference: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "# Model configuration\n",
    "chatgpt_model ='gpt-4o'\n",
    "#chatgpt_model ='gpt-3.5-turbo'\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Sentences\"):  \n",
    "    start_time = time.time()              \n",
    "    try:\n",
    "        # ==========================================================================================================================\n",
    "        text = row['text'] \n",
    "        output_string, formatted_prompt, input_count, output_count = split_sentence_chatgpt(text, splitting_prompt, chatgpt_model, temperature, top_p)\n",
    "        \n",
    "        # Validate output format\n",
    "        if not output_string:  \n",
    "            raise ValueError(f\"Output is empty.\")\n",
    "        try:\n",
    "            output_string = ast.literal_eval(output_string)  \n",
    "            print(f\"Output is in list format.\") \n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            raise ValueError(f\"Output not in list format: {e}\")\n",
    "\n",
    "        for generated_sent in output_string:\n",
    "            \n",
    "            # Classify the text\n",
    "            pred_class, probs = classify_text(model, generated_sent, device)\n",
    "            \n",
    "            # =========================================================================================================================\n",
    "            # If mixed class, retry Splitting  and Classification \n",
    "            if pred_class == 'MIX':\n",
    "                print('Found MIX sentence, retry splitting and classification ...')\n",
    "                new_output_string, new_formatted_prompt, new_input_count, new_output_count = split_sentence_chatgpt(generated_sent, splitting_prompt, chatgpt_model, temperature, top_p)\n",
    "                \n",
    "                # Validate output format\n",
    "                if not new_output_string:  \n",
    "                    raise ValueError(f\"Output is empty.\")\n",
    "                try:\n",
    "                    new_output_string = ast.literal_eval(new_output_string)  \n",
    "                    print(f\"Output is in list format.\") \n",
    "                except (SyntaxError, ValueError) as e:\n",
    "                    raise ValueError(f\"Output not in list format: {e}\")\n",
    "                \n",
    "                for new_generated_sent in new_output_string:\n",
    "                    # Classify the text\n",
    "                    new_pred_class, new_probs = classify_text(model, new_generated_sent, device)\n",
    "\n",
    "                    score = rouge(new_generated_sent, text)\n",
    "                \n",
    "                    results.append({\n",
    "                        'text_id': row['text_id'],\n",
    "                        'text': text,\n",
    "                        'prompt': new_formatted_prompt,\n",
    "                        'generated_sent': new_generated_sent,\n",
    "                        'pred_sent_class': new_pred_class,\n",
    "                        'probs': new_probs,\n",
    "                        'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "                        'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "                        'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "                        'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "                        'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "                        'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "                        'output_string': new_output_string,\n",
    "                        'input_count': new_input_count,\n",
    "                        'output_count': new_output_count,\n",
    "                        'errors': None,\n",
    "                        'elapsed_time_sec': time.time() - start_time\n",
    "                    })\n",
    "            # =========================================================================================================================\n",
    "            # Process non-MIX class directly\n",
    "            else:\n",
    "                score = rouge(generated_sent, text)\n",
    "                \n",
    "                results.append({\n",
    "                    'text_id': row['text_id'],\n",
    "                    'text': text,\n",
    "                    'prompt': formatted_prompt,\n",
    "                    'generated_sent': generated_sent,\n",
    "                    'pred_sent_class': pred_class,\n",
    "                    'probs': probs,\n",
    "                    'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "                    'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "                    'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "                    'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "                    'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "                    'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "                    'output_string': output_string,\n",
    "                    'input_count': input_count,\n",
    "                    'output_count': output_count,\n",
    "                    'errors': None,\n",
    "                    'elapsed_time_sec': time.time() - start_time\n",
    "                })\n",
    "\n",
    "    # Process Errors =======================================================================================\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['text_id']}: {str(e)}\")\n",
    "        results.append({\n",
    "            'text_id': row['text_id'],\n",
    "            'text': text,\n",
    "            'prompt': formatted_prompt,\n",
    "            'generated_sent': None,\n",
    "            'pred_sent_class': None,\n",
    "            'probs': None,\n",
    "            'rouge1_precision': None,\n",
    "            'rouge3_precision': None,\n",
    "            'rouge5_precision': None,\n",
    "            'rouge7_precision': None,\n",
    "            'rouge9_precision': None,\n",
    "            'rougeL_precision': None,\n",
    "            'output_string': output_string,\n",
    "            'input_count': None,\n",
    "            'output_count': None,\n",
    "            'errors': str(e),\n",
    "            'elapsed_time_sec': time.time() - start_time\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(f\"/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_{patent_id}_{IPC}_{chatgpt_model}.xlsx\", index=False)\n",
    "##results_df.to_excel(f\"/home/fantoni/patent-sentence-classification/results/first_claim_{patent_id}_{IPC}_{chatgpt_model}_temp_{temperature}_top_{top_p}_asis.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to rephrase the following text while keeping the original words unchanged.\n",
      "Follow these steps in sequence:\n",
      "1. Rephrase the text into Subject-Verb-Object (SVO) structure.\n",
      "2. Do not use any past participle verbs in your rephrased version.\n",
      "\n",
      "Input: \"{text}\"\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Prompt Definition\n",
    "##task = \"\"\"Your task is to generate a summary of a given text. Maintain the original words without any changes.\\n\"\"\" # summarize\n",
    "##task = \"\"\"Your task is to rephrase a text. Maintain the original words without any changes.\\n\"\"\" # rephrase\n",
    "task = \"\"\"Your task is to rephrase the following text while keeping the original words unchanged.\n",
    "Follow these steps in sequence:\n",
    "1. Rephrase the text into Subject-Verb-Object (SVO) structure.\n",
    "2. Do not use any past participle verbs in your rephrased version.\n",
    "\"\"\" \n",
    "\n",
    "output_format = \"Input: \\\"{text}\\\"\\nOutput:\"\n",
    "rephrasing_prompt = '\\n'.join([task, output_format])\n",
    "print(rephrasing_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Rephrasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def rephrase_with_chatgpt(input_text, prompt, model=\"gpt-4o\", temperature=0, top_p=1):\n",
    "    \n",
    "    # Define a prompt template for classification\n",
    "    prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "    # Create an OpenAI LLM instance\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_retries=1,\n",
    "        max_tokens=1000 \n",
    "    )\n",
    "\n",
    "    # Create a runnable sequence\n",
    "    split_sentence_chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    # Format prompt\n",
    "    formatted_prompt = prompt_template.format(text=input_text)\n",
    "    #print(f\"Generated Prompt:\\n{formatted_prompt}\") # Debugging statement\n",
    "\n",
    "    # Perform Classification\n",
    "    output_string = split_sentence_chain.invoke({\"text\": input_text}).strip()\n",
    "\n",
    "    # Calculate token count\n",
    "    input_count = count_tokens(formatted_prompt)\n",
    "    output_count = count_tokens(output_string)\n",
    "\n",
    "    print(f\"Using: model = '{model}'; temperature = {temperature}; top_p = {top_p}\")\n",
    "\n",
    "    return output_string, formatted_prompt, input_count, output_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:   7%|▋         | 1/14 [00:00<00:06,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  14%|█▍        | 2/14 [00:01<00:08,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  21%|██▏       | 3/14 [00:02<00:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  29%|██▊       | 4/14 [00:03<00:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  36%|███▌      | 5/14 [00:03<00:07,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  43%|████▎     | 6/14 [00:04<00:06,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  50%|█████     | 7/14 [00:05<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  57%|█████▋    | 8/14 [00:06<00:04,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  64%|██████▍   | 9/14 [00:06<00:03,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  71%|███████▏  | 10/14 [00:07<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  79%|███████▊  | 11/14 [00:08<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  86%|████████▌ | 12/14 [00:08<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  93%|█████████▎| 13/14 [00:40<00:10, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 14/14 [00:42<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: model = 'gpt-3.5-turbo'; temperature = 0; top_p = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load data\n",
    "#file_path = '/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_WO-2019021161-A1_F16D65-12_gpt-4o'\n",
    "#file_path = '/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_WO-2019243958-A1_F16D55-288_gpt-4o'\n",
    "#file_path = '/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_WO-2020058819-A1_B6078-1706_gpt-4o'\n",
    "#file_path = '/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_WO-2022144719-A1_B6078-261_gpt-4o'\n",
    "#file_path ='/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_WO-2017216367-A1_C08J5-0405_gpt-4o'\n",
    "#file_path = '/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_US-10733341-B1_G06F30-30_gpt-4o'\n",
    "#file_path = '/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_IT-201900008253-A1_B65G1-023_gpt-4o'\n",
    "\n",
    "df = pd.read_excel(f\"{file_path}.xlsx\", usecols=['text_id', 'text', 'generated_sent', 'pred_sent_class', 'probs'])\n",
    "\n",
    "# Model configuration\n",
    "#chatgpt_model = 'gpt-4o'\n",
    "chatgpt_model = 'gpt-3.5-turbo'\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "\n",
    "# Add new columns\n",
    "df['prompt'] = None\n",
    "df['rephrased_sent'] = None\n",
    "df['rouge1_precision'] = None\n",
    "df['rouge3_precision'] = None\n",
    "df['rouge5_precision'] = None\n",
    "df['rouge7_precision'] = None\n",
    "df['rouge9_precision'] = None\n",
    "df['rougeL_precision'] = None\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Sentences\"):\n",
    "    try:\n",
    "        text = row['generated_sent']\n",
    "        rephrased_text, formatted_prompt, input_count, output_count = rephrase_with_chatgpt(text, rephrasing_prompt, chatgpt_model, temperature, top_p)\n",
    "\n",
    "        if not rephrased_text:\n",
    "            raise ValueError(\"Output is empty.\")\n",
    "\n",
    "        # Save rephrased sentence\n",
    "        df.at[i, 'prompt'] = formatted_prompt\n",
    "        df.at[i, 'rephrased_sent'] = rephrased_text\n",
    "\n",
    "        # Evaluate Rephrasing\n",
    "        score = rouge(text, rephrased_text)\n",
    "        df.at[i, 'rouge1_precision'] = round(score['rouge1_precision'].item(), 3)\n",
    "        df.at[i, 'rouge3_precision'] = round(score['rouge3_precision'].item(), 3)\n",
    "        df.at[i, 'rouge5_precision'] = round(score['rouge5_precision'].item(), 3)\n",
    "        df.at[i, 'rouge7_precision'] = round(score['rouge7_precision'].item(), 3)\n",
    "        df.at[i, 'rouge9_precision'] = round(score['rouge9_precision'].item(), 3)\n",
    "        df.at[i, 'rougeL_precision'] = round(score['rougeL_precision'].item(), 3)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {i}: {e}\")\n",
    "\n",
    "df.to_excel(f\"{file_path}_rephrased.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prova Codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A method of administering a wagering game, comprising:\n",
      "accepting an ante wager from a player by receiving a chip on a surface of a table;\n",
      "dealing a partial hand to the player from a set of randomly ordered cards and permitting the player to view the partial hand;\n",
      "after permitting the player to view the at least one card and while prohibiting the player from folding, accepting from the player an initial election to check after offering the player initial options selected from the group consisting of check or place a play wager of a first value;\n",
      "dealing at least one other card from the set available to the player to form a complete hand and permitting the player to view the at least one other card;\n",
      "after permitting the player to view the at least one other card, accepting from the player a subsequent election to place a play wager of a second, lesser value by receiving another chip on the surface of the table after offering the player subsequent options selected from the group consisting of fold or place the play wager of the second value or less;\n",
      "resolving the ante wager and the play wager. \n",
      "-------------------------\n",
      " \n",
      "-------------------------\n",
      " \n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import Sentences\n",
    "results_df = pd.read_excel('/home/fantoni/patent-sentence-classification/results/first_claim_US20200074811A1_G07F17_gpt-4o_temp_0_top_1_asis.xlsx')\n",
    "\n",
    "# Cluster Sentneces based on Predicted Class\n",
    "strings_FUN = []\n",
    "strings_STR = [] \n",
    "strings_OTH = []\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    if row['pred_sent_class'] == 'FUN' or row['pred_sent_class'] == 'MIX':\n",
    "        string = row['generated_sent']\n",
    "        strings_FUN.append(string)\n",
    "    elif row['pred_sent_class'] == 'STR' or row['pred_sent_class'] == 'MIX':\n",
    "        string = row['generated_sent']\n",
    "        strings_STR.append(string)\n",
    "    elif row['pred_sent_class'] == 'OTH' :\n",
    "        string = row['generated_sent']\n",
    "        strings_OTH.append(string)\n",
    "    \n",
    "strings_FUN = '\\n'.join(strings_FUN); print(strings_FUN, '\\n-------------------------')\n",
    "strings_STR = '\\n'.join(strings_STR); print(strings_STR, '\\n-------------------------')\n",
    "strings_OTH = '\\n'.join(strings_OTH); print(strings_OTH, '\\n-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_model ='gpt-4o'\n",
    "#chatgpt_model ='gpt-3.5-turbo'\n",
    "\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "\n",
    "# Peform Summarization\n",
    "FUN_summary, formatted_prompt, input_count, output_count = summarize_with_chatgpt(strings_FUN, summary_prompt, chatgpt_model)\n",
    "STR_summary, formatted_prompt, input_count, output_count = summarize_with_chatgpt(strings_STR, summary_prompt, chatgpt_model)\n",
    "\n",
    "# Print Summary\n",
    "print('FUN:', FUN_summary, '\\n-------------------------')\n",
    "print('STR:', STR_summary, '\\n-------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
