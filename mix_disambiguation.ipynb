{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain Import\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Finetuned Model Import\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from src.model import PatentSentenceClassifier\n",
    "\n",
    "# Load OpenaAI API key\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to divide a given sentence into sub-sentences.\n",
      "Insert periods to divide the sentence into meaningful sub-sentences. \n",
      "Maintain the original words without any changes. \n",
      "Do not use pronouns; instead, repeat the original subjects as needed.\n",
      "\n",
      "Input Format: A single sentence.\n",
      "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
      "\n",
      "Input: \"{text}\"\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Prompt Definition\n",
    "task = \"\"\"Your task is to divide a given sentence into sub-sentences.\n",
    "Insert periods to divide the sentence into meaningful sub-sentences. \n",
    "Maintain the original words without any changes. \n",
    "Do not use pronouns; instead, repeat the original subjects as needed.\n",
    "\n",
    "Input Format: A single sentence.\n",
    "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
    "\"\"\"\n",
    "output_format = \"Input: \\\"{text}\\\"\\nOutput:\"\n",
    "splitting_prompt = '\\n'.join([task, output_format])\n",
    "print(splitting_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def split_sentence_chatgpt(input_text, prompt, model=\"gpt-4o\", temperature=0, top_p=1):\n",
    "    \n",
    "    # Define a prompt template for classification\n",
    "    prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "    # Create an OpenAI LLM instance\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_retries=1,\n",
    "        max_tokens=1000 \n",
    "    )\n",
    "\n",
    "    # Create a runnable sequence\n",
    "    split_sentence_chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    # Format prompt\n",
    "    formatted_prompt = prompt_template.format(text=input_text)\n",
    "    #print(f\"Generated Prompt:\\n{formatted_prompt}\") # Debugging statement\n",
    "\n",
    "    # Perform Classification\n",
    "    output_string = split_sentence_chain.invoke({\"text\": input_text}).strip()\n",
    "\n",
    "    # Calculate token count\n",
    "    input_count = count_tokens(formatted_prompt)\n",
    "    output_count = count_tokens(output_string)\n",
    "\n",
    "    print(f\"\\tUsing: model = '{model}'; temperature = {temperature}; top_p = {top_p}\")\n",
    "\n",
    "    return output_string, formatted_prompt, input_count, output_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Sentence Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Sentences from test set\n",
    "test_df = pd.read_excel(\"/home/fantoni/patent-sentence-classification/data/1200_agreement_All.xlsx\")\n",
    "test_df = test_df.query(\"agreement==True & sent_tag_mc == 'MIX'\")\n",
    "input_text = df['sent'].iloc[3] # select by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    }
   ],
   "source": [
    "# Select Model\n",
    "chatgpt_model ='gpt-3.5-turbo'\n",
    "\n",
    "# Perfrom Sentence Splitting\n",
    "output_string, formatted_prompt, input_count, output_count = split_sentence_chatgpt(input_text, splitting_prompt, chatgpt_model)\n",
    "\n",
    "# Validate Output Format\n",
    "if not output_string:  \n",
    "    raise ValueError(f\"Output is empty.\")\n",
    "try:\n",
    "    output_string = ast.literal_eval(output_string.replace('\\n', ''))\n",
    "    print(f\"Output is in list format.\") \n",
    "except (SyntaxError, ValueError) as e:\n",
    "    raise ValueError(f\"Output not in list format: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "input_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generated_sent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rouge1_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge3_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge5_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge7_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rouge9_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rougeL_precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "output_string",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "input_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "output_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f42ca208-e48f-4294-8e6e-b9297de12241",
       "rows": [
        [
         "0",
         "The recovery of the ingestible device may be performed in a similar manner as embodiments described in U.S.",
         "Divide the given sentence into sub-sentences by inserting periods. Maintain the original words without any changes. Do not use pronouns. Repeat the original subjects as needed.\n\nInput Format: A single sentence.\nOutput Format: A list of sub-sentences, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n\nInput: 'The recovery of the ingestible device may be performed in a similar manner as embodiments described in U.S.' \nOutput:",
         "The recovery of the ingestible device may be performed in a similar manner as embodiments described in U.S.",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "1.0",
         "['The recovery of the ingestible device may be performed in a similar manner as embodiments described in U.S.']",
         "106",
         "22"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_sent</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge3_precision</th>\n",
       "      <th>rouge5_precision</th>\n",
       "      <th>rouge7_precision</th>\n",
       "      <th>rouge9_precision</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>output_string</th>\n",
       "      <th>input_count</th>\n",
       "      <th>output_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The recovery of the ingestible device may be p...</td>\n",
       "      <td>Divide the given sentence into sub-sentences b...</td>\n",
       "      <td>The recovery of the ingestible device may be p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[The recovery of the ingestible device may be ...</td>\n",
       "      <td>106</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  The recovery of the ingestible device may be p...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Divide the given sentence into sub-sentences b...   \n",
       "\n",
       "                                      generated_sent  rouge1_precision  \\\n",
       "0  The recovery of the ingestible device may be p...               1.0   \n",
       "\n",
       "   rouge3_precision  rouge5_precision  rouge7_precision  rouge9_precision  \\\n",
       "0               1.0               1.0               1.0               1.0   \n",
       "\n",
       "   rougeL_precision                                      output_string  \\\n",
       "0               1.0  [The recovery of the ingestible device may be ...   \n",
       "\n",
       "   input_count  output_count  \n",
       "0          106            22  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize ROUGE scorer\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "results = []\n",
    "\n",
    "for generated_sent in output_string:\n",
    "    score = rouge(generated_sent, input_text)\n",
    "\n",
    "    results.append({\n",
    "        'input_text': input_text,\n",
    "        'prompt': formatted_prompt,\n",
    "        'generated_sent': generated_sent,\n",
    "        #'pred_sent_class': pre_class,\n",
    "        #'probs': probs,\n",
    "        'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "        'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "        'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "        'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "        'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "        'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "        'output_string': output_string,\n",
    "        'input_count': input_count,\n",
    "        'output_count': output_count,\n",
    "        #'errors': None,\n",
    "        #'elapsed_time_sec': time.time() - start_time()\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sentence Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Base Tokenizer loaded succesfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at anferico/bert-for-patents and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model loaded succesfully.\n",
      "\n",
      "Finetuned model loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set path to checkpoint\n",
    "checkpoint_name = 'bert-large-uncased_train_10_7'; model_name = \"bert-large-uncased\"\n",
    "checkpoint_name = 'bert-for-patents_train_10_7'; model_name = \"anferico/bert-for-patents\" # https://huggingface.co/anferico/bert-for-patents\n",
    "checkpoint_path = f\"/home/fantoni/patent-sentence-classification/models/finetuning/{checkpoint_name}.ckpt\"\n",
    "\n",
    "# Load Base Tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "print('\\nBase Tokenizer loaded succesfully.')\n",
    "\n",
    "# Load Base Model\n",
    "base_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "print('\\nBase model loaded succesfully.')\n",
    "\n",
    "# Load Finetuned Model\n",
    "model = PatentSentenceClassifier.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    model=base_model,\n",
    "    tokenizer=bert_tokenizer)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print('\\nFinetuned model loaded succesfully.')\n",
    "\n",
    "# Define Finetuned Tokenizer\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(model, input_text, device='cpu'):\n",
    "    \n",
    "    # Tokenize input\n",
    "    tokenizer = model.tokenizer  # Assuming tokenizer is part of the model\n",
    "    inputs = tokenizer(input_text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Move input to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Define label mapping\n",
    "    int_to_label = {0: 'FUN', 1: 'STR', 2: 'MIX', 3: 'OTH'}\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0]\n",
    "        pred_idx = torch.argmax(probs).item()\n",
    "        pred_class = int_to_label[pred_idx]\n",
    "\n",
    "    return pred_class, [round(p, 2) for p in probs.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  48%|████▊     | 24/50 [02:01<01:41,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing sentence 1394724: Output not in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 50/50 [04:02<00:00,  4.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize ROUGE scorer\n",
    "# reference: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "# Import Sentences\n",
    "test_df = pd.read_excel(\"/home/fantoni/patent-sentence-classification/data/1200_agreement_All.xlsx\")\n",
    "test_df = test_df.query(\"agreement==True & sent_tag_mc == 'MIX'\")\n",
    "test_df = test_df.head(50) \n",
    "\n",
    "# Select Models\n",
    "chatgpt_model ='gpt-3.5-turbo'\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing Sentences\"):  \n",
    "    start_time = time.time()              \n",
    "    try:\n",
    "        original_sent = row['sent']\n",
    "        \n",
    "        # Split Sentence \n",
    "        output_string, formatted_prompt, input_count, output_count = split_sentence_chatgpt(original_sent, splitting_prompt, chatgpt_model)\n",
    "\n",
    "        # Validate Output Format\n",
    "        if not output_string:  \n",
    "            raise ValueError(f\"Output is empty.\")\n",
    "        try:\n",
    "            # Convert string to list\n",
    "            output_string = ast.literal_eval(output_string)  \n",
    "            #print(f\"Output is in list format.\") \n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            raise ValueError(f\"Output not in list format: {e}\")\n",
    "\n",
    "        # Iterate over the generated sentences\n",
    "        for generated_sent in output_string:\n",
    "\n",
    "            # Classify Sub-Sentences\n",
    "            pre_class, probs = classify_text(model, generated_sent, device)\n",
    "\n",
    "            # Compute ROUGE Score\n",
    "            score = rouge(generated_sent, original_sent)\n",
    "            \n",
    "            # Append Results\n",
    "            results.append({\n",
    "                'sent_id': row['sent_id'],\n",
    "                'original_sent_class': row['sent_tag_mc'],\n",
    "                'original_sent': original_sent,\n",
    "                'prompt': formatted_prompt,\n",
    "                'generated_sent': generated_sent,\n",
    "                'pred_sent_class': pre_class,\n",
    "                'probs': probs,\n",
    "                'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "                'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "                'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "                'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "                'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "                'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "                'output_string': output_string,\n",
    "                'input_count': input_count,\n",
    "                'output_count': output_count,\n",
    "                'errors': None,\n",
    "                'elapsed_time_sec': time.time() - start_time\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['sent_id']}: {str(e)}\")\n",
    "        results.append({\n",
    "            'sent_id': row['sent_id'],\n",
    "            'original_sent_class': row['sent_tag_mc'],\n",
    "            'original_sent': original_sent,\n",
    "            'prompt': formatted_prompt,\n",
    "            'generated_sent': None,\n",
    "            'pred_sent_class': None,\n",
    "            'probs': None,\n",
    "            'rouge1_precision': None,\n",
    "            'rouge3_precision': None,\n",
    "            'rouge5_precision': None,\n",
    "            'rouge7_precision': None,\n",
    "            'rouge9_precision': None,\n",
    "            'rougeL_precision': None,\n",
    "            'output_string': output_string,\n",
    "            'input_count': None,\n",
    "            'output_count': None,\n",
    "            'errors': str(e),\n",
    "            'elapsed_time_sec': time.time() - start_time\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "\n",
    "# Save results to Excel\n",
    "results_df.to_excel(\"/home/fantoni/patent-sentence-classification/results/mix_disambiguation.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A method of administering a wagering game, comprising:\n",
      "accepting an ante wager from a player by receiving a chip on a surface of a table;\n",
      "dealing a partial hand to the player from a set of randomly ordered cards and permitting the player to view the partial hand;\n",
      "after permitting the player to view the at least one card and while prohibiting the player from folding, accepting from the player an initial election to check after offering the player initial options selected from the group consisting of check or place a play wager of a first value;\n",
      "dealing at least one other card from the set available to the player to form a complete hand and permitting the player to view the at least one other card;\n",
      "after permitting the player to view the at least one other card, accepting from the player a subsequent election to place a play wager of a second, lesser value by receiving another chip on the surface of the table after offering the player subsequent options selected from the group consisting of fold or place the play wager of the second value or less; and\n",
      "resolving the ante wager and the play wager.\n"
     ]
    }
   ],
   "source": [
    "# Select patent\n",
    "#patent_id = 'US8695121B2'; IPC = 'A42B3' \n",
    "#patent_id = 'US11133720B2'; IPC = 'H02K3' \n",
    "#patent_id = 'US9468782B2'; IPC = 'A62B23' \n",
    "#patent_id = 'US11673469B2'; IPC = 'B60K37'\n",
    "patent_id = 'US20200074811A1'; IPC = 'G07F17'\n",
    "\n",
    "# Import Sentences\n",
    "df = pd.read_excel(f\"/home/fantoni/patent-sentence-classification/data/patents/{patent_id}_{IPC}.xlsx\")\n",
    "input_text = df[df['section'] == 'first_claim']['sent'].iloc[0] # get first claim\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Splitting\n",
    "\n",
    "reference: https://community.openai.com/t/different-results-same-prompt-on-openai-api-vs-chatgpt/1062995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7f3ee467-493d-47a0-9d8c-703fbb75fef7",
       "rows": [
        [
         "0",
         "1",
         "1. A method of administering a wagering game, comprising:\naccepting an ante wager from a player by receiving a chip on a surface of a table;\ndealing a partial hand to the player from a set of randomly ordered cards and permitting the player to view the partial hand;\nafter permitting the player to view the at least one card and while prohibiting the player from folding, accepting from the player an initial election to check after offering the player initial options selected from the group consisting of check or place a play wager of a first value;\ndealing at least one other card from the set available to the player to form a complete hand and permitting the player to view the at least one other card;\nafter permitting the player to view the at least one other card, accepting from the player a subsequent election to place a play wager of a second, lesser value by receiving another chip on the surface of the table after offering the player subsequent options selected from the group consisting of fold or place the play wager of the second value or less; and\nresolving the ante wager and the play wager."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1. A method of administering a wagering game, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text\n",
       "0        1  1. A method of administering a wagering game, ..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Chunking approach: divide first claim into chunks using simple regex\n",
    "chunks = [sent.replace('\\n', ' ') + '.' for sent in re.split(r'(?:;\\sand\\n)', input_text)]\n",
    "df = pd.DataFrame({'text_id': range(1, len(chunks)+1), 'text': chunks})\n",
    "\n",
    "# 2. As-Is approach: use first claim as is\n",
    "df = pd.DataFrame({'text_id': [1], 'text': input_text})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing: model = 'gpt-4o'; temperature = 0; top_p = 1\n",
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 1/1 [00:21<00:00, 21.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize ROUGE scorer\n",
    "# reference: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "chatgpt_model ='gpt-4o'\n",
    "#chatgpt_model ='gpt-3.5-turbo'\n",
    "\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Sentences\"):  \n",
    "    start_time = time.time()              \n",
    "    try:\n",
    "        text = row['text'] \n",
    "        output_string, formatted_prompt, input_count, output_count = split_sentence_chatgpt(text, splitting_prompt, chatgpt_model, temperature, top_p)\n",
    "\n",
    "        if not output_string:  \n",
    "            raise ValueError(f\"Output is empty.\")\n",
    "        try:\n",
    "            output_string = ast.literal_eval(output_string)  \n",
    "            print(f\"Output is in list format.\") \n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            raise ValueError(f\"Output not in list format: {e}\")\n",
    "\n",
    "        for generated_sent in output_string:\n",
    "            pre_class, probs = classify_text(model, generated_sent, device)\n",
    "            score = rouge(generated_sent, text)\n",
    "            \n",
    "            results.append({\n",
    "                'text_id': row['text_id'],\n",
    "                'text': text,\n",
    "                'prompt': formatted_prompt,\n",
    "                'generated_sent': generated_sent,\n",
    "                'pred_sent_class': pre_class,\n",
    "                'probs': probs,\n",
    "                'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "                'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "                'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "                'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "                'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "                'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "                'output_string': output_string,\n",
    "                'input_count': input_count,\n",
    "                'output_count': output_count,\n",
    "                'errors': None,\n",
    "                'elapsed_time_sec': time.time() - start_time\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['text_id']}: {str(e)}\")\n",
    "        results.append({\n",
    "            'text_id': row['text_id'],\n",
    "            'text': text,\n",
    "            'prompt': formatted_prompt,\n",
    "            'generated_sent': None,\n",
    "            'pred_sent_class': None,\n",
    "            'probs': None,\n",
    "            'rouge1_precision': None,\n",
    "            'rouge3_precision': None,\n",
    "            'rouge5_precision': None,\n",
    "            'rouge7_precision': None,\n",
    "            'rouge9_precision': None,\n",
    "            'rougeL_precision': None,\n",
    "            'output_string': output_string,\n",
    "            'input_count': None,\n",
    "            'output_count': None,\n",
    "            'errors': str(e),\n",
    "            'elapsed_time_sec': time.time() - start_time\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(f\"/home/fantoni/patent-sentence-classification/results/first_claim_{patent_id}_{IPC}_{chatgpt_model}_temp_{temperature}_top_{top_p}_asis.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Prompts for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to generate a summary of a given text. Maintain the original words without any changes.\n",
      "\n",
      "Input: \"{text}\"\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Prompt Definition\n",
    "task = \"\"\"Your task is to generate a summary of a given text. Maintain the original words without any changes.\\n\"\"\" # summarize\n",
    "#task = \"\"\"Your task is to rephrase a text. Maintain the original words without any changes.\\n\"\"\" # rephrase\n",
    "\n",
    "output_format = \"Input: \\\"{text}\\\"\\nOutput:\"\n",
    "summary_prompt = '\\n'.join([task, output_format])\n",
    "print(summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A method of administering a wagering game, comprising:\n",
      "accepting an ante wager from a player by receiving a chip on a surface of a table;\n",
      "dealing a partial hand to the player from a set of randomly ordered cards and permitting the player to view the partial hand;\n",
      "after permitting the player to view the at least one card and while prohibiting the player from folding, accepting from the player an initial election to check after offering the player initial options selected from the group consisting of check or place a play wager of a first value;\n",
      "dealing at least one other card from the set available to the player to form a complete hand and permitting the player to view the at least one other card;\n",
      "after permitting the player to view the at least one other card, accepting from the player a subsequent election to place a play wager of a second, lesser value by receiving another chip on the surface of the table after offering the player subsequent options selected from the group consisting of fold or place the play wager of the second value or less;\n",
      "resolving the ante wager and the play wager. \n",
      "-------------------------\n",
      " \n",
      "-------------------------\n",
      " \n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import Sentences\n",
    "results_df = pd.read_excel('/home/fantoni/patent-sentence-classification/results/first_claim_US20200074811A1_G07F17_gpt-4o_temp_0_top_1_asis.xlsx')\n",
    "\n",
    "# Cluster Sentneces based on Predicted Class\n",
    "strings_FUN = []\n",
    "strings_STR = [] \n",
    "strings_OTH = []\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    if row['pred_sent_class'] == 'FUN' or row['pred_sent_class'] == 'MIX':\n",
    "        string = row['generated_sent']\n",
    "        strings_FUN.append(string)\n",
    "    elif row['pred_sent_class'] == 'STR' or row['pred_sent_class'] == 'MIX':\n",
    "        string = row['generated_sent']\n",
    "        strings_STR.append(string)\n",
    "    elif row['pred_sent_class'] == 'OTH' :\n",
    "        string = row['generated_sent']\n",
    "        strings_OTH.append(string)\n",
    "    \n",
    "strings_FUN = '\\n'.join(strings_FUN); print(strings_FUN, '\\n-------------------------')\n",
    "strings_STR = '\\n'.join(strings_STR); print(strings_STR, '\\n-------------------------')\n",
    "strings_OTH = '\\n'.join(strings_OTH); print(strings_OTH, '\\n-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def summarize_with_chatgpt(input_text, prompt, model=\"gpt-4o\", temperature=0, top_p=1):\n",
    "    \n",
    "    # Define a prompt template for classification\n",
    "    prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "    # Create an OpenAI LLM instance\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_retries=1,\n",
    "        max_tokens=1000 \n",
    "    )\n",
    "\n",
    "    # Create a runnable sequence\n",
    "    split_sentence_chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    # Format prompt\n",
    "    formatted_prompt = prompt_template.format(text=input_text)\n",
    "    #print(f\"Generated Prompt:\\n{formatted_prompt}\") # Debugging statement\n",
    "\n",
    "    # Perform Classification\n",
    "    output_string = split_sentence_chain.invoke({\"text\": input_text}).strip()\n",
    "\n",
    "    # Calculate token count\n",
    "    input_count = count_tokens(formatted_prompt)\n",
    "    output_count = count_tokens(output_string)\n",
    "\n",
    "    print(f\"\\tUsing: model = '{model}'; temperature = {temperature}; top_p = {top_p}\")\n",
    "\n",
    "    return output_string, formatted_prompt, input_count, output_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing: model = 'gpt-4o'; temperature = 0; top_p = 1\n",
      "\tUsing: model = 'gpt-4o'; temperature = 0; top_p = 1\n"
     ]
    }
   ],
   "source": [
    "chatgpt_model ='gpt-4o'\n",
    "#chatgpt_model ='gpt-3.5-turbo'\n",
    "\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "\n",
    "# Peform Summarization\n",
    "FUN_summary, formatted_prompt, input_count, output_count = summarize_with_chatgpt(strings_FUN, summary_prompt, chatgpt_model)\n",
    "STR_summary, formatted_prompt, input_count, output_count = summarize_with_chatgpt(strings_STR, summary_prompt, chatgpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUN: A method of administering a wagering game involves accepting an ante wager, dealing a partial hand, allowing the player to view it, and offering options to check or place a play wager. After dealing additional cards to form a complete hand, the player can place a lesser play wager or fold. The game concludes by resolving the wagers. \n",
      "-------------------------\n",
      "STR: The input text is empty, so there is nothing to summarize. \n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print Summary\n",
    "print('FUN:', FUN_summary, '\\n-------------------------')\n",
    "print('STR:', STR_summary, '\\n-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Summary: rouge and number of words\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "summary_data = []\n",
    "for summary in [FUN_summary, STR_summary]:\n",
    "    claim = input_text.replace('\\n', ' ')\n",
    "    token_summary = count_tokens(summary)\n",
    "    token_claim = count_tokens(claim)\n",
    "    score = rouge(summary, claim)\n",
    "    summary_data.append({\n",
    "        'first_claim': claim,\n",
    "        'summary': summary,\n",
    "        'token_claim': token_claim,\n",
    "        'token_summary': token_summary,\n",
    "        'token_summary_%': round((token_summary*100/token_claim), 2),\n",
    "        'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "        'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "        'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "        'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "        'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "        'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_excel(f\"/home/fantoni/patent-sentence-classification/results/summary_{patent_id}_{IPC}_{chatgpt_model}_temp_{temperature}_top_{top_p}_asis.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
