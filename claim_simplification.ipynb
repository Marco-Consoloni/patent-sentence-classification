{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a478216",
   "metadata": {},
   "source": [
    "# Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b58494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain Import\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Finetuned Model Import\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from src.model import PatentSentenceClassifier\n",
    "\n",
    "# Load OpenaAI API key\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b942931",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c836468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def calculate_rouge_scores_precision(text1, text2, rouge_scorer):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores precision between two texts.\n",
    "    \n",
    "    Parameters:\n",
    "    - text1: First text for comparison (typically the generated or processed text)\n",
    "    - text2: Second text for comparison (typically the original reference text)\n",
    "    - rouge_scorer: Initialized ROUGEScore object\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary containing rounded ROUGE precision scores\n",
    "    \"\"\"\n",
    "    score = rouge_scorer(text1, text2)\n",
    "    \n",
    "    return {\n",
    "        'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "        'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "        'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "        'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "        'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "        'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "    }\n",
    "\n",
    "def prompt_chatgpt(input_text, input_context, prompt, model=\"gpt-4o\", temperature=0, top_p=1):\n",
    "    \n",
    "    # Define a prompt template for classification\n",
    "    prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "    # Create an OpenAI LLM instance\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_retries=1,\n",
    "        max_tokens=1000 \n",
    "    )\n",
    "\n",
    "    # Create a runnable sequence\n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    # Prepare inputs\n",
    "    inputs = {\"input_text\": input_text}\n",
    "    if input_context:\n",
    "        inputs[\"input_context\"] = input_context\n",
    "\n",
    "    # Format prompt\n",
    "    formatted_prompt = prompt_template.format(**inputs)\n",
    "    ##print(f\"Generated Prompt:\\n{formatted_prompt}\") # Debugging statement\n",
    "\n",
    "    # Invoke Chain\n",
    "    output_string = chain.invoke(inputs).strip()\n",
    "\n",
    "    # Calculate token count\n",
    "    #input_count = count_tokens(formatted_prompt)\n",
    "    #output_count = count_tokens(output_string)\n",
    "\n",
    "    #print(f\"Using: model = '{model}'; temperature = {temperature}; top_p = {top_p}\") # Debugging statement\n",
    "\n",
    "    return output_string, formatted_prompt\n",
    "\n",
    "\n",
    "def classify_text(model, input_text, device='cpu'):\n",
    "    \n",
    "    # Tokenize input\n",
    "    tokenizer = model.tokenizer  # Assuming tokenizer is part of the model\n",
    "    inputs = tokenizer(input_text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Move input to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Define label mapping\n",
    "    int_to_label = {0: 'FUN', 1: 'STR', 2: 'MIX', 3: 'OTH'}\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0]\n",
    "        pred_idx = torch.argmax(probs).item()\n",
    "        pred_class = int_to_label[pred_idx]\n",
    "\n",
    "    return pred_class, [round(p, 2) for p in probs.tolist()]\n",
    "\n",
    "\n",
    "def create_hierarchy(text):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        text (str): A multiline string where each line begins with one or more '>' characters to indicate hierarchy.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the following columns:\n",
    "            - 'index': Hierarchical index (e.g., '1', '1.1', '1.1.1')\n",
    "            - 'sentence': The textual content of the line\n",
    "            - 'parent_indices': List of parent index strings\n",
    "            - 'parents': List of parent content strings\n",
    "    \"\"\"\n",
    "    \n",
    "    lines = text.strip().splitlines()\n",
    "    counters = []\n",
    "    index_sentence_dict = {}\n",
    "    rows = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Remove the leading '>' used to denote the root node level\n",
    "        line = line[1:]  # The first '>' is always present, even for root-level items\n",
    "        \n",
    "        # Determine level by counting leading '>' characters\n",
    "        level = len(line) - len(line.lstrip('>'))\n",
    "        content = line.lstrip('>').strip()\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        # Adjust counters for current level\n",
    "        if len(counters) <= level:\n",
    "            counters += [1] * (level + 1 - len(counters))\n",
    "        else:\n",
    "            counters = counters[:level + 1]\n",
    "            counters[level] += 1\n",
    "\n",
    "        # Build Index\n",
    "        index = \".\".join(map(str, counters[:level + 1]))\n",
    "        index_sentence_dict[index] = content\n",
    "\n",
    "        # Generate parent indices and content inline\n",
    "        parent_indices = [\".\".join(map(str, counters[:i])) for i in range(1, level + 1)]\n",
    "        parent_contents = [index_sentence_dict[pidx] for pidx in parent_indices if pidx in index_sentence_dict]\n",
    "\n",
    "        rows.append({\n",
    "            \"index\": index,\n",
    "            \"text\": content,\n",
    "            \"parent_indices\": parent_indices,\n",
    "            \"parents\": parent_contents\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def append_result_to_list(results, index, input_text, context=None, rephrasing_prompt=None, \n",
    "                         rephrased_text=None, splitting_prompt=None, sentence=None, \n",
    "                         pred_class=None, probs=None, rouge_scores=None, error=None):\n",
    "    \"\"\"\n",
    "    Append a single result entry to the results list.\n",
    "    \n",
    "    Parameters:\n",
    "    - results: The list to append results to\n",
    "    - index: Index level of the hyerarchy\n",
    "    - input_text: Original claim text\n",
    "    - context: Parent claim context if available\n",
    "    - rephrasing_prompt: Prompt used for rephrasing\n",
    "    - rephrased_text: Text after rephrasing\n",
    "    - splitting_prompt: Prompt used for splitting\n",
    "    - sentence: Current sentence being processed\n",
    "    - pred_class: Predicted classification\n",
    "    - probs: Classification probabilities\n",
    "    - rouge_scores: Dict of ROUGE scores (keys: rouge1_precision, rouge3_precision, etc.)\n",
    "    - error: Error message if processing failed\n",
    "    \n",
    "    Returns:\n",
    "    - The updated results list\n",
    "    \"\"\"\n",
    "    # Create base result dictionary\n",
    "    result = {\n",
    "        'index': index,\n",
    "        'text': input_text,\n",
    "        'context': context,\n",
    "        'rephrasing_prompt': rephrasing_prompt,\n",
    "        'rephrased_text': rephrased_text,\n",
    "        'splitting_prompt': splitting_prompt,\n",
    "        'sentence': sentence,\n",
    "        'pred_class': pred_class,\n",
    "        'probs': probs,\n",
    "        'rouge1_precision': None,\n",
    "        'rouge3_precision': None,\n",
    "        'rouge5_precision': None,\n",
    "        'rouge7_precision': None,\n",
    "        'rouge9_precision': None,\n",
    "        'rougeL_precision': None,\n",
    "        'errors': error\n",
    "    }\n",
    "    \n",
    "    # Update with ROUGE scores if provided\n",
    "    if rouge_scores and not error:\n",
    "        result.update(rouge_scores)\n",
    "    \n",
    "    # Append to results list\n",
    "    results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ef006",
   "metadata": {},
   "source": [
    "# Prompts Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb1fdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to format the following patent claim by indenting each logical block of information.\n",
      "Use  \">\" characters to indent the beginning of each block. \n",
      "\n",
      "\"{input_text}\"\n",
      "\n",
      "Your task is to split the given text into sub-sentences, ensuring that:\n",
      "1. Each sub-sentence must contain only one predicate.\n",
      "2. Avoid using pronouns. Instead, repeat the original subject explicitly where needed.\n",
      "3. Do not split inline lists; treat item lists as a single unit.\n",
      "\n",
      "Use the provided context (if any) to resolve references and pronouns in the main text.\n",
      "\n",
      "Context Format: Supplementary information providing background for the main text.\n",
      "Input Format: The main text that is to be split.\n",
      "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
      "\n",
      "Context: \"{input_context}\"\n",
      "Input: \"{input_text}\"\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Prompt to indent claim\n",
    "indenting_prompt = \"\"\"Your task is to format the following patent claim by indenting each logical block of information.\n",
    "Use  \">\" characters to indent the beginning of each block. \n",
    "\n",
    "\\\"{input_text}\\\"\n",
    "\"\"\"\n",
    "print(indenting_prompt)\n",
    "\n",
    "# =========================================================================================\n",
    "# Prompt to rephrase a text using its context\n",
    "rephrasing_with_context_prompt = \"\"\"Your task is to rephrase the given text into Subject-Verb-Object (SVO) structure.\n",
    "Avoid using pronouns. Instead, repeat the original subject explicitly where needed.\n",
    "\n",
    "Use the provided context (if any) to resolve references and pronouns in the main text.\n",
    "\n",
    "Context Format: Supplementary information providing background for the main text.\n",
    "Input Format: The main text that is to be rephrased.\n",
    "\n",
    "Context: \\\"{input_context}\\\"\n",
    "Input: \\\"{input_text}\\\"\n",
    "Output:\"\"\" \n",
    "\n",
    "# =========================================================================================\n",
    "# Prompt to split a text into sub-sentences using its context\n",
    "splitting_with_context_prompt = \"\"\"Your task is to split the given text into sub-sentences, ensuring that:\n",
    "1. Each sub-sentence must contain only one predicate.\n",
    "2. Avoid using pronouns. Instead, repeat the original subject explicitly where needed.\n",
    "3. Do not split inline lists; treat item lists as a single unit.\n",
    "\n",
    "Use the provided context (if any) to resolve references and pronouns in the main text.\n",
    "\n",
    "Context Format: Supplementary information providing background for the main text.\n",
    "Input Format: The main text that is to be split.\n",
    "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
    "\n",
    "Context: \\\"{input_context}\\\"\n",
    "Input: \\\"{input_text}\\\"\n",
    "Output:\n",
    "\"\"\"\n",
    "print(splitting_with_context_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff027ed4",
   "metadata": {},
   "source": [
    "# Load Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1c2eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Base Tokenizer loaded succesfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at anferico/bert-for-patents and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base model loaded succesfully.\n",
      "\n",
      "Finetuned model loaded succesfully. Using: 'bert-for-patents_train_10_4'\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set path to checkpoint\n",
    "checkpoint_name = 'bert-large-uncased_train_10_4'; model_name = \"bert-large-uncased\"\n",
    "checkpoint_name = 'bert-for-patents_train_10_4'; model_name = \"anferico/bert-for-patents\" \n",
    "checkpoint_path = f\"/home/fantoni/patent-sentence-classification/models/finetuning/{checkpoint_name}.ckpt\"\n",
    "\n",
    "# Load Base Tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "print('\\nBase Tokenizer loaded succesfully.')\n",
    "\n",
    "# Load Base Model\n",
    "base_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "print('\\nBase model loaded succesfully.')\n",
    "\n",
    "# Load Finetuned Model\n",
    "model = PatentSentenceClassifier.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    model=base_model,\n",
    "    tokenizer=bert_tokenizer)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"\\nFinetuned model loaded succesfully. Using: '{checkpoint_name}'\")\n",
    "\n",
    "# Define Finetuned Tokenizer\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169764a",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9c0a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A helmet system for removing condensation from a user's field of vision, comprising: a helmet shell having an anterior section, a posterior section, and a venting passage, wherein the helmet shell defines an internal cavity that is in fluid communication with a front portion of the venting passage, and wherein the internal cavity is configured to receive the user's head; a visor coupled with the helmet shell, wherein at least part of the visor defines part of the internal cavity; a humidity sensor positioned within the internal cavity of the helmet shell; and a ventilation system comprising: a base coupled with the helmet shell, wherein the base has a first venting aperture in fluid communication with a rear portion of the venting passage, a base cover coupled with the base, wherein the base cover has a second venting aperture, an air movement assembly disposed between the base and the base cover, wherein the air movement assembly provides fluid communication between the first venting aperture and the second venting aperture, a switch, a power source, and a circuit card comprising: a first input configured to receive a signal from the humidity sensor, a second input configured to receive a second signal from the switch, a first module configured to determine a first instruction for the air movement assembly based on the signal received from the humidity sensor, a second module configured to determine a second instruction for the air movement assembly based on the second signal received from the switch, a first output configured to transmit the first instruction to the air movement assembly, wherein activation of the air movement assembly based on the first instruction operates to remove condensation from the user's field of vision by moving a volume of air of the internal cavity of the helmet shell through the venting passage and moving the volume of air through the second venting aperture of the base cover between the anterior section and the posterior section, and a second output configured to transmit the second instruction to the air movement assembly, wherein the second instruction controls whether power is delivered to the air movement assembly and controls whether the air movement assembly directs air flow from the first venting aperture toward the second venting aperture or from the second venting aperture toward the first venting aperture.\n"
     ]
    }
   ],
   "source": [
    "# Patents\n",
    "filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/US8695121B2_A42B3.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/US11133720B2_H02K3.txt\"\n",
    "\n",
    "# Pavanello Patents\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/IT-201900008253-A1_B65G1-023.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/US-10733341-B1_G06F30-30.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2017216367-A1_C08J5-0405.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2019021161-A1_F16D65-12.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2019243958-A1_F16D55-288.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2020058819-A1_B6078-1706.txt\"\n",
    "#filepath = \"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2022144719-A1_B6078-261.txt\"\n",
    "\n",
    "with open(filepath, \"r\") as file:\n",
    "    input_text = file.read()\n",
    "    print(input_text)\n",
    "\n",
    "# Set file name\n",
    "filename = os.path.splitext(os.path.basename(filepath))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fa694",
   "metadata": {},
   "source": [
    "# Extract Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79c2ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1. A helmet system for removing condensation from a user's field of vision, comprising:\n",
      ">>a helmet shell having an anterior section, a posterior section, and a venting passage, wherein the helmet shell defines an internal cavity that is in fluid communication with a front portion of the venting passage, and wherein the internal cavity is configured to receive the user's head;\n",
      ">>a visor coupled with the helmet shell, wherein at least part of the visor defines part of the internal cavity;\n",
      ">>a humidity sensor positioned within the internal cavity of the helmet shell; and\n",
      ">>a ventilation system comprising:\n",
      ">>>a base coupled with the helmet shell, wherein the base has a first venting aperture in fluid communication with a rear portion of the venting passage,\n",
      ">>>a base cover coupled with the base, wherein the base cover has a second venting aperture,\n",
      ">>>an air movement assembly disposed between the base and the base cover, wherein the air movement assembly provides fluid communication between the first venting aperture and the second venting aperture,\n",
      ">>>a switch,\n",
      ">>>a power source, and\n",
      ">>>a circuit card comprising:\n",
      ">>>>a first input configured to receive a signal from the humidity sensor,\n",
      ">>>>a second input configured to receive a second signal from the switch,\n",
      ">>>>a first module configured to determine a first instruction for the air movement assembly based on the signal received from the humidity sensor,\n",
      ">>>>a second module configured to determine a second instruction for the air movement assembly based on the second signal received from the switch,\n",
      ">>>>a first output configured to transmit the first instruction to the air movement assembly, wherein activation of the air movement assembly based on the first instruction operates to remove condensation from the user's field of vision by moving a volume of air of the internal cavity of the helmet shell through the venting passage and moving the volume of air through the second venting aperture of the base cover between the anterior section and the posterior section, and\n",
      ">>>>a second output configured to transmit the second instruction to the air movement assembly, wherein the second instruction controls whether power is delivered to the air movement assembly and controls whether the air movement assembly directs air flow from the first venting aperture toward the second venting aperture or from the second venting aperture toward the first venting aperture.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parent_indices",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "parents",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fa02b7b9-bbf6-4046-b302-18a4e44dbdc5",
       "rows": [
        [
         "0",
         "1",
         "1. A helmet system for removing condensation from a user's field of vision, comprising:",
         "[]",
         "[]"
        ],
        [
         "1",
         "1.1",
         "a helmet shell having an anterior section, a posterior section, and a venting passage, wherein the helmet shell defines an internal cavity that is in fluid communication with a front portion of the venting passage, and wherein the internal cavity is configured to receive the user's head;",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "2",
         "1.2",
         "a visor coupled with the helmet shell, wherein at least part of the visor defines part of the internal cavity;",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "3",
         "1.3",
         "a humidity sensor positioned within the internal cavity of the helmet shell; and",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "4",
         "1.4",
         "a ventilation system comprising:",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "5",
         "1.4.1",
         "a base coupled with the helmet shell, wherein the base has a first venting aperture in fluid communication with a rear portion of the venting passage,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "6",
         "1.4.2",
         "a base cover coupled with the base, wherein the base cover has a second venting aperture,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "7",
         "1.4.3",
         "an air movement assembly disposed between the base and the base cover, wherein the air movement assembly provides fluid communication between the first venting aperture and the second venting aperture,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "8",
         "1.4.4",
         "a switch,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "9",
         "1.4.5",
         "a power source, and",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "10",
         "1.4.6",
         "a circuit card comprising:",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "11",
         "1.4.6.1",
         "a first input configured to receive a signal from the humidity sensor,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "12",
         "1.4.6.2",
         "a second input configured to receive a second signal from the switch,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "13",
         "1.4.6.3",
         "a first module configured to determine a first instruction for the air movement assembly based on the signal received from the humidity sensor,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "14",
         "1.4.6.4",
         "a second module configured to determine a second instruction for the air movement assembly based on the second signal received from the switch,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "15",
         "1.4.6.5",
         "a first output configured to transmit the first instruction to the air movement assembly, wherein activation of the air movement assembly based on the first instruction operates to remove condensation from the user's field of vision by moving a volume of air of the internal cavity of the helmet shell through the venting passage and moving the volume of air through the second venting aperture of the base cover between the anterior section and the posterior section, and",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "16",
         "1.4.6.6",
         "a second output configured to transmit the second instruction to the air movement assembly, wherein the second instruction controls whether power is delivered to the air movement assembly and controls whether the air movement assembly directs air flow from the first venting aperture toward the second venting aperture or from the second venting aperture toward the first venting aperture.",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 17
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>parent_indices</th>\n",
       "      <th>parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1. A helmet system for removing condensation f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>a helmet shell having an anterior section, a p...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>a visor coupled with the helmet shell, wherein...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>a humidity sensor positioned within the intern...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>a ventilation system comprising:</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.4.1</td>\n",
       "      <td>a base coupled with the helmet shell, wherein ...</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4.2</td>\n",
       "      <td>a base cover coupled with the base, wherein th...</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.4.3</td>\n",
       "      <td>an air movement assembly disposed between the ...</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.4.4</td>\n",
       "      <td>a switch,</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.4.5</td>\n",
       "      <td>a power source, and</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.4.6</td>\n",
       "      <td>a circuit card comprising:</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.4.6.1</td>\n",
       "      <td>a first input configured to receive a signal f...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.4.6.2</td>\n",
       "      <td>a second input configured to receive a second ...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.4.6.3</td>\n",
       "      <td>a first module configured to determine a first...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.4.6.4</td>\n",
       "      <td>a second module configured to determine a seco...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.4.6.5</td>\n",
       "      <td>a first output configured to transmit the firs...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.4.6.6</td>\n",
       "      <td>a second output configured to transmit the sec...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text  \\\n",
       "0         1  1. A helmet system for removing condensation f...   \n",
       "1       1.1  a helmet shell having an anterior section, a p...   \n",
       "2       1.2  a visor coupled with the helmet shell, wherein...   \n",
       "3       1.3  a humidity sensor positioned within the intern...   \n",
       "4       1.4                   a ventilation system comprising:   \n",
       "5     1.4.1  a base coupled with the helmet shell, wherein ...   \n",
       "6     1.4.2  a base cover coupled with the base, wherein th...   \n",
       "7     1.4.3  an air movement assembly disposed between the ...   \n",
       "8     1.4.4                                          a switch,   \n",
       "9     1.4.5                                a power source, and   \n",
       "10    1.4.6                         a circuit card comprising:   \n",
       "11  1.4.6.1  a first input configured to receive a signal f...   \n",
       "12  1.4.6.2  a second input configured to receive a second ...   \n",
       "13  1.4.6.3  a first module configured to determine a first...   \n",
       "14  1.4.6.4  a second module configured to determine a seco...   \n",
       "15  1.4.6.5  a first output configured to transmit the firs...   \n",
       "16  1.4.6.6  a second output configured to transmit the sec...   \n",
       "\n",
       "     parent_indices                                            parents  \n",
       "0                []                                                 []  \n",
       "1               [1]  [1. A helmet system for removing condensation ...  \n",
       "2               [1]  [1. A helmet system for removing condensation ...  \n",
       "3               [1]  [1. A helmet system for removing condensation ...  \n",
       "4               [1]  [1. A helmet system for removing condensation ...  \n",
       "5          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "6          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "7          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "8          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "9          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "10         [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "11  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "12  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "13  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "14  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "15  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "16  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indent text with prompt\n",
    "output_string, _ = prompt_chatgpt(input_text=input_text, input_context=None, prompt=indenting_prompt, model='gpt-3.5-turbo')\n",
    "print(output_string)\n",
    "\n",
    "df = create_hierarchy(output_string)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d02b5f",
   "metadata": {},
   "source": [
    "# Rephrasing + Splitting + Classification\n",
    "\n",
    "different results ChatGPT and API ChatGPT : https://community.openai.com/t/different-results-same-prompt-on-openai-api-vs-chatgpt/1062995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d82740ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Claim Texts:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Claim Texts: 100%|██████████| 17/17 [01:50<00:00,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /home/fantoni/patent-sentence-classification/results/claim_simplification/US8695121B2_A42B3_gpt-4o.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "\n",
    "# Initialize ROUGE scorer with various n-gram options\n",
    "# reference: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
    "rouge_scorer = ROUGEScore(rouge_keys=('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "# Model configuration\n",
    "CHATGPT_MODEL = 'gpt-4o'\n",
    "#CHATGPT_MODEL = 'gpt-3.5-turbo'\n",
    "TEMPERATURE = 0\n",
    "TOP_P = 1\n",
    "\n",
    "# Main processing loop\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Claim Texts\"):  \n",
    "    try:\n",
    "        input_text = row['text']\n",
    "        index = row['index']\n",
    "        word_count = len(re.findall(r'\\b\\w+\\b', input_text))\n",
    "        input_context = None\n",
    "        rephrasing_prompt = None\n",
    "        splitting_prompt = None\n",
    "\n",
    "        # Case 1: Short text ending with colon - classification only\n",
    "        # Rephrasing such sentences using contextual information can cause errors in the BOM hierarchy, \n",
    "        # so they are classified without rephrasing.\n",
    "        if input_text.endswith(':') and word_count <= 20:\n",
    "            \n",
    "            # Perform Classification\n",
    "            pred_class, probs = classify_text(model, input_text, device)\n",
    "            \n",
    "            # Calculate rouge scores\n",
    "            rouge_scores = calculate_rouge_scores_precision(input_text, input_text, rouge_scorer)\n",
    "            \n",
    "            # Append results using our new function\n",
    "            append_result_to_list(\n",
    "                results, \n",
    "                index, \n",
    "                input_text, \n",
    "                sentence=input_text, \n",
    "                pred_class=pred_class, \n",
    "                probs=probs, \n",
    "                rouge_scores=rouge_scores\n",
    "            )\n",
    "\n",
    "        # Case 2: Text with parents or long text - rephrasing, splitting and classification\n",
    "        elif row['parents'] or word_count >= 20:\n",
    "            \n",
    "            # 1. Get context from parent claims if available\n",
    "            n_parents = 1  # Number of parent claims to include\n",
    "            input_context = ' '.join(row['parents'][-n_parents:]) if row['parents'] else ' '\n",
    "            \n",
    "            # 2. Rephrase text using context\n",
    "            rephrased_text, rephrasing_prompt = prompt_chatgpt(input_text, input_context, rephrasing_with_context_prompt, CHATGPT_MODEL, TEMPERATURE, TOP_P)\n",
    "            \n",
    "            # 3. Split text into sub-sentences\n",
    "            split_text, splitting_prompt = prompt_chatgpt(rephrased_text, input_context, splitting_with_context_prompt, CHATGPT_MODEL, TEMPERATURE, TOP_P)\n",
    "            \n",
    "            # Validate output format\n",
    "            if not split_text:\n",
    "                raise ValueError(\"Output is empty.\")\n",
    "    \n",
    "            try:\n",
    "                split_text = ast.literal_eval(split_text)\n",
    "            except (SyntaxError, ValueError) as e:\n",
    "                raise ValueError(f\"Output not in list format: {e}\")\n",
    "            \n",
    "            # 4. Process each sub-sentence\n",
    "            for sent in split_text:\n",
    "                # Classify sub-sentence\n",
    "                pred_class, probs = classify_text(model, sent, device)\n",
    "                \n",
    "                # Calculate rouge scores\n",
    "                rouge_scores = calculate_rouge_scores_precision(sent, input_text, rouge_scorer)\n",
    "                \n",
    "                # Append results using our new function\n",
    "                append_result_to_list(\n",
    "                    results, \n",
    "                    index, \n",
    "                    input_text, \n",
    "                    context=input_context,\n",
    "                    rephrasing_prompt=rephrasing_prompt,\n",
    "                    rephrased_text=rephrased_text,\n",
    "                    splitting_prompt=splitting_prompt,\n",
    "                    sentence=sent,\n",
    "                    pred_class=pred_class, \n",
    "                    probs=probs, \n",
    "                    rouge_scores=rouge_scores\n",
    "                )\n",
    "\n",
    "        # Case 3: Simple sentences without parents (root sentence) - classification only\n",
    "        else:\n",
    "            # Perform Classification\n",
    "            pred_class, probs = classify_text(model, input_text, device)\n",
    "            \n",
    "            # Calculate rouge scores\n",
    "            rouge_scores = calculate_rouge_scores_precision(input_text, input_text, rouge_scorer)\n",
    "            \n",
    "            # Append results using our new function\n",
    "            append_result_to_list(\n",
    "                results, \n",
    "                index, \n",
    "                input_text, \n",
    "                sentence=input_text, \n",
    "                pred_class=pred_class, \n",
    "                probs=probs, \n",
    "                rouge_scores=rouge_scores\n",
    "            )\n",
    "\n",
    "    # Handle errors\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing claim {row['index']}: {str(e)}\")\n",
    "        append_result_to_list(\n",
    "            results,\n",
    "            index,\n",
    "            input_text,\n",
    "            error=str(e)\n",
    "        )\n",
    "\n",
    "# Create DataFrame from results and save to Excel\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_excel(f\"/home/fantoni/patent-sentence-classification/results/claim_simplification/{filename}_{CHATGPT_MODEL}.xlsx\", index=False)   \n",
    "print(f\"Results saved to /home/fantoni/patent-sentence-classification/results/claim_simplification/{filename}_{CHATGPT_MODEL}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa546c",
   "metadata": {},
   "source": [
    "# Prova Codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba1c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:   9%|▉         | 1/11 [00:09<01:31,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  18%|█▊        | 2/11 [00:19<01:27,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  27%|██▋       | 3/11 [00:28<01:16,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  36%|███▋      | 4/11 [00:36<01:00,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  45%|████▌     | 5/11 [00:42<00:47,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  55%|█████▍    | 6/11 [00:47<00:34,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  64%|██████▎   | 7/11 [00:54<00:27,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  73%|███████▎  | 8/11 [01:00<00:19,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MIX sentence, retry splitting and classification ...\n",
      "Error processing sentence 8: name 'split_sentence_chatgpt' is not defined\n",
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  82%|████████▏ | 9/11 [01:06<00:13,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MIX sentence, retry splitting and classification ...\n",
      "Error processing sentence 9: name 'split_sentence_chatgpt' is not defined\n",
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences:  91%|█████████ | 10/11 [01:14<00:06,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MIX sentence, retry splitting and classification ...\n",
      "Error processing sentence 10: name 'split_sentence_chatgpt' is not defined\n",
      "Output is in list format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentences: 100%|██████████| 11/11 [01:22<00:00,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MIX sentence, retry splitting and classification ...\n",
      "Error processing sentence 11: name 'split_sentence_chatgpt' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize ROUGE scorer with various n-gram options\n",
    "# reference: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "rouge = ROUGEScore(rouge_keys = ('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "# Model configuration\n",
    "#chatgpt_model ='gpt-4o'\n",
    "chatgpt_model ='gpt-3.5-turbo'\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Sentences\"):  \n",
    "    start_time = time.time()              \n",
    "    try:\n",
    "        # ==========================================================================================================================\n",
    "        # Split text into sub-sentences\n",
    "        text = row['text']\n",
    "        output_string, formatted_prompt, input_count, output_count = prompt_chatgpt(text, splitting_prompt, chatgpt_model, temperature, top_p)\n",
    "        \n",
    "        # Validate output format\n",
    "        if not output_string:  \n",
    "            raise ValueError(f\"Output is empty.\")\n",
    "        try:\n",
    "            output_string = ast.literal_eval(output_string)  \n",
    "            print(f\"Output is in list format.\") \n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            raise ValueError(f\"Output not in list format: {e}\")\n",
    "\n",
    "        for generated_sent in output_string:\n",
    "            \n",
    "            # Classify the text\n",
    "            pred_class, probs = classify_text(model, generated_sent, device)\n",
    "            \n",
    "            # =========================================================================================================================\n",
    "            # If mixed class, retry Splitting  and Classification \n",
    "            if pred_class == 'MIX':\n",
    "                print('Found MIX sentence, retry splitting and classification ...')\n",
    "                new_output_string, new_formatted_prompt, new_input_count, new_output_count = prompt_chatgpt(generated_sent, splitting_prompt, chatgpt_model, temperature, top_p)\n",
    "                \n",
    "                # Validate output format\n",
    "                if not new_output_string:  \n",
    "                    raise ValueError(f\"Output is empty.\")\n",
    "                try:\n",
    "                    new_output_string = ast.literal_eval(new_output_string)  \n",
    "                    print(f\"Output is in list format.\") \n",
    "                except (SyntaxError, ValueError) as e:\n",
    "                    raise ValueError(f\"Output not in list format: {e}\")\n",
    "                \n",
    "                for new_generated_sent in new_output_string:\n",
    "                    # Classify the text\n",
    "                    new_pred_class, new_probs = classify_text(model, new_generated_sent, device)\n",
    "\n",
    "                    score = rouge(new_generated_sent, text)\n",
    "                \n",
    "                    results.append({\n",
    "                        'text_id': row['text_id'],\n",
    "                        'text': text,\n",
    "                        'prompt': new_formatted_prompt,\n",
    "                        'generated_sent': new_generated_sent,\n",
    "                        'pred_sent_class': new_pred_class,\n",
    "                        'probs': new_probs,\n",
    "                        'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "                        'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "                        'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "                        'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "                        'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "                        'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "                        'output_string': new_output_string,\n",
    "                        'input_count': new_input_count,\n",
    "                        'output_count': new_output_count,\n",
    "                        'errors': None,\n",
    "                        'elapsed_time_sec': time.time() - start_time\n",
    "                    })\n",
    "            # =========================================================================================================================\n",
    "            # Process non-MIX class directly\n",
    "            else:\n",
    "                score = rouge(generated_sent, text)\n",
    "                \n",
    "                results.append({\n",
    "                    'text_id': row['text_id'],\n",
    "                    'text': text,\n",
    "                    'prompt': formatted_prompt,\n",
    "                    'generated_sent': generated_sent,\n",
    "                    'pred_sent_class': pred_class,\n",
    "                    'probs': probs,\n",
    "                    'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "                    'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "                    'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "                    'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "                    'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "                    'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "                    'output_string': output_string,\n",
    "                    'input_count': input_count,\n",
    "                    'output_count': output_count,\n",
    "                    'errors': None,\n",
    "                    'elapsed_time_sec': time.time() - start_time\n",
    "                })\n",
    "\n",
    "    # Process Errors =======================================================================================\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['text_id']}: {str(e)}\")\n",
    "        results.append({\n",
    "            'text_id': row['text_id'],\n",
    "            'text': text,\n",
    "            'prompt': formatted_prompt,\n",
    "            'generated_sent': None,\n",
    "            'pred_sent_class': None,\n",
    "            'probs': None,\n",
    "            'rouge1_precision': None,\n",
    "            'rouge3_precision': None,\n",
    "            'rouge5_precision': None,\n",
    "            'rouge7_precision': None,\n",
    "            'rouge9_precision': None,\n",
    "            'rougeL_precision': None,\n",
    "            'output_string': output_string,\n",
    "            'input_count': None,\n",
    "            'output_count': None,\n",
    "            'errors': str(e),\n",
    "            'elapsed_time_sec': time.time() - start_time\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(f\"/home/fantoni/patent-sentence-classification/results/mix_disambiguation/first_claim_{patent_id}_{IPC}_{chatgpt_model}.xlsx\", index=False)\n",
    "##results_df.to_excel(f\"/home/fantoni/patent-sentence-classification/results/first_claim_{patent_id}_{IPC}_{chatgpt_model}_temp_{temperature}_top_{top_p}_asis.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Tree\n",
    "tree = build_tree_with_parents(output_string)\n",
    "\n",
    "# Create Dataframe from Tree\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        'text_id': idx + 1,\n",
    "        'text': node['line'],\n",
    "        'context': ' '.join(node['parents'])\n",
    "    }\n",
    "    for idx, node in enumerate(tree)\n",
    "])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
