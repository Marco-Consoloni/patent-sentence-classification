{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a478216",
   "metadata": {},
   "source": [
    "# 1. Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b58494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import ast\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain Import\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Finetuned Model Import\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from src.model import PatentSentenceClassifier\n",
    "\n",
    "# Load OpenaAI API key\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b942931",
   "metadata": {},
   "source": [
    "# 2. Utils\n",
    "\n",
    "This section defines the main functions that are utilized throughout the remainder of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c836468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def calculate_rouge_scores_precision(text1, text2, rouge_scorer):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores precision between two texts.\n",
    "    \n",
    "    Parameters:\n",
    "    - text1: First text for comparison (typically the generated or processed text)\n",
    "    - text2: Second text for comparison (typically the original reference text)\n",
    "    - rouge_scorer: Initialized ROUGEScore object\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary containing rounded ROUGE precision scores\n",
    "    \"\"\"\n",
    "    score = rouge_scorer(text1, text2)\n",
    "    \n",
    "    return {\n",
    "        'rouge1_precision': round(score['rouge1_precision'].item(), 3),\n",
    "        'rouge3_precision': round(score['rouge3_precision'].item(), 3),\n",
    "        'rouge5_precision': round(score['rouge5_precision'].item(), 3),\n",
    "        'rouge7_precision': round(score['rouge7_precision'].item(), 3),\n",
    "        'rouge9_precision': round(score['rouge9_precision'].item(), 3),\n",
    "        'rougeL_precision': round(score['rougeL_precision'].item(), 3),\n",
    "    }\n",
    "\n",
    "def prompt_chatgpt(input_text, input_context, prompt, model=\"gpt-4o\", temperature=0, top_p=1):\n",
    "    \n",
    "    # Define a prompt template for classification\n",
    "    prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "    # Create an OpenAI LLM instance\n",
    "    llm = ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_retries=1,\n",
    "        max_tokens=1000 \n",
    "    )\n",
    "\n",
    "    # Create a runnable sequence\n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "    # Prepare inputs\n",
    "    inputs = {\"input_text\": input_text}\n",
    "    if input_context:\n",
    "        inputs[\"input_context\"] = input_context\n",
    "\n",
    "    # Format prompt\n",
    "    formatted_prompt = prompt_template.format(**inputs)\n",
    "    ##print(f\"Generated Prompt:\\n{formatted_prompt}\") # Debugging statement\n",
    "\n",
    "    # Invoke Chain\n",
    "    output_string = chain.invoke(inputs).strip()\n",
    "\n",
    "    # Calculate token count\n",
    "    #input_count = count_tokens(formatted_prompt)\n",
    "    #output_count = count_tokens(output_string)\n",
    "\n",
    "    #print(f\"Using: model = '{model}'; temperature = {temperature}; top_p = {top_p}\") # Debugging statement\n",
    "\n",
    "    return output_string, formatted_prompt\n",
    "\n",
    "\n",
    "def classify_text(model, input_text, device='cpu'):\n",
    "    \n",
    "    # Tokenize input\n",
    "    tokenizer = model.tokenizer  # Assuming tokenizer is part of the model\n",
    "    inputs = tokenizer(input_text, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Move input to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Define label mapping\n",
    "    int_to_label = {0: 'FUN', 1: 'STR', 2: 'MIX', 3: 'OTH'}\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)[0]\n",
    "        pred_idx = torch.argmax(probs).item()\n",
    "        pred_class = int_to_label[pred_idx]\n",
    "\n",
    "    return pred_class, [round(p, 2) for p in probs.tolist()]\n",
    "\n",
    "\n",
    "def create_hierarchy(text):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        text (str): A multiline string where each line begins with one or more '>' characters to indicate hierarchy.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the following columns:\n",
    "            - 'index': Hierarchical index (e.g., '1', '1.1', '1.1.1')\n",
    "            - 'sentence': The textual content of the line\n",
    "            - 'parent_indices': List of parent index strings\n",
    "            - 'parents': List of parent content strings\n",
    "    \"\"\"\n",
    "    \n",
    "    lines = text.strip().splitlines()\n",
    "    counters = []\n",
    "    index_sentence_dict = {}\n",
    "    rows = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Remove the leading '>' used to denote the root node level\n",
    "        line = line[1:]  # The first '>' is always present, even for root-level items\n",
    "        \n",
    "        # Determine level by counting leading '>' characters\n",
    "        level = len(line) - len(line.lstrip('>'))\n",
    "        content = line.lstrip('>').strip()\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        # Adjust counters for current level\n",
    "        if len(counters) <= level:\n",
    "            counters += [1] * (level + 1 - len(counters))\n",
    "        else:\n",
    "            counters = counters[:level + 1]\n",
    "            counters[level] += 1\n",
    "\n",
    "        # Build Index\n",
    "        index = \".\".join(map(str, counters[:level + 1]))\n",
    "        index_sentence_dict[index] = content\n",
    "\n",
    "        # Generate parent indices and content inline\n",
    "        parent_indices = [\".\".join(map(str, counters[:i])) for i in range(1, level + 1)]\n",
    "        parent_contents = [index_sentence_dict[pidx] for pidx in parent_indices if pidx in index_sentence_dict]\n",
    "\n",
    "        rows.append({\n",
    "            \"index\": index,\n",
    "            \"text\": content,\n",
    "            \"parent_indices\": parent_indices,\n",
    "            \"parents\": parent_contents\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def append_result_to_list(results, index, input_text, context=None, rephrasing_prompt=None, \n",
    "                         rephrased_text=None, splitting_prompt=None, sentence=None, \n",
    "                         pred_class=None, probs=None, rouge_scores=None, error=None):\n",
    "    \"\"\"\n",
    "    Append a single result entry to the results list.\n",
    "    \n",
    "    Parameters:\n",
    "    - results: The list to append results to\n",
    "    - index: Index level of the hyerarchy\n",
    "    - input_text: Original claim text\n",
    "    - context: Parent claim context if available\n",
    "    - rephrasing_prompt: Prompt used for rephrasing\n",
    "    - rephrased_text: Text after rephrasing\n",
    "    - splitting_prompt: Prompt used for splitting\n",
    "    - sentence: Current sentence being processed\n",
    "    - pred_class: Predicted classification\n",
    "    - probs: Classification probabilities\n",
    "    - rouge_scores: Dict of ROUGE scores (keys: rouge1_precision, rouge3_precision, etc.)\n",
    "    - error: Error message if processing failed\n",
    "    \n",
    "    Returns:\n",
    "    - The updated results list\n",
    "    \"\"\"\n",
    "    # Create base result dictionary\n",
    "    result = {\n",
    "        'index': index,\n",
    "        'text': input_text,\n",
    "        'context': context,\n",
    "        'rephrasing_prompt': rephrasing_prompt,\n",
    "        'rephrased_text': rephrased_text,\n",
    "        'splitting_prompt': splitting_prompt,\n",
    "        'sentence': sentence,\n",
    "        'pred_class': pred_class,\n",
    "        'probs': probs,\n",
    "        'rouge1_precision': None,\n",
    "        'rouge3_precision': None,\n",
    "        'rouge5_precision': None,\n",
    "        'rouge7_precision': None,\n",
    "        'rouge9_precision': None,\n",
    "        'rougeL_precision': None,\n",
    "        'errors': error\n",
    "    }\n",
    "    \n",
    "    # Update with ROUGE scores if provided\n",
    "    if rouge_scores and not error:\n",
    "        result.update(rouge_scores)\n",
    "    \n",
    "    # Append to results list\n",
    "    results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ef006",
   "metadata": {},
   "source": [
    "# 3. Prompts Definition\n",
    "\n",
    "This section defines the prompts that are utilized throughout the remainder of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1fdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to format the following patent claim by indenting each logical block of information.\n",
      "Use  \">\" characters to indent the beginning of each block. \n",
      "\n",
      "\"{input_text}\"\n",
      "\n",
      "Your task is to split the given text into sub-sentences, ensuring that:\n",
      "1. Each sub-sentence must contain only one predicate.\n",
      "2. Avoid using pronouns. Instead, repeat the original subject explicitly where needed.\n",
      "3. Do not split inline lists; treat item lists as a single unit.\n",
      "\n",
      "Use the provided context (if any) to resolve references and pronouns in the main text.\n",
      "\n",
      "Context Format: Supplementary information providing background for the main text.\n",
      "Input Format: The main text that is to be split.\n",
      "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
      "\n",
      "Context: \"{input_context}\"\n",
      "Input: \"{input_text}\"\n",
      "Output:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Prompt to indent claim\n",
    "indenting_prompt = \"\"\"Your task is to format the following patent claim by indenting each logical block of information.\n",
    "Use  \">\" characters to indent the beginning of each block. \n",
    "\n",
    "\\\"{input_text}\\\"\n",
    "\"\"\"\n",
    "print(indenting_prompt)\n",
    "\n",
    "# =========================================================================================\n",
    "# Prompt to rephrase a text using its context\n",
    "rephrasing_with_context_prompt = \"\"\"Your task is to rephrase the given text into Subject-Verb-Object (SVO) structure.\n",
    "Avoid using pronouns. Instead, repeat the original subject explicitly where needed.\n",
    "\n",
    "Use the provided context (if any) to resolve references and pronouns in the main text.\n",
    "\n",
    "Context Format: Supplementary information providing background for the main text.\n",
    "Input Format: The main text that is to be rephrased.\n",
    "\n",
    "Context: \\\"{input_context}\\\"\n",
    "Input: \\\"{input_text}\\\"\n",
    "Output:\"\"\" \n",
    "\n",
    "# =========================================================================================\n",
    "# Prompt to split a text into sub-sentences using its context\n",
    "splitting_with_context_prompt = \"\"\"Your task is to split the given text into sub-sentences, ensuring that:\n",
    "1. Each sub-sentence must contain only one predicate.\n",
    "2. Avoid using pronouns. Instead, repeat the original subject explicitly where needed.\n",
    "3. Do not split inline lists; treat item lists as a single unit.\n",
    "\n",
    "Use the provided context (if any) to resolve references and pronouns in the main text.\n",
    "\n",
    "Context Format: Supplementary information providing background for the main text.\n",
    "Input Format: The main text that is to be split.\n",
    "Output Format: A list of sub-sentences enclosed in double quotes, separated by commas (e.g., [\"sub-sentence1\", \"sub-sentence2\", \"sub-sentence3\"]).\n",
    "\n",
    "Context: \\\"{input_context}\\\"\n",
    "Input: \\\"{input_text}\\\"\n",
    "Output:\n",
    "\"\"\"\n",
    "print(splitting_with_context_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff027ed4",
   "metadata": {},
   "source": [
    "# 4. Load Classification Model\n",
    "\n",
    "In this section, we load the classification model used to categorize claim sentences into four classes: FUN (Functional), STR (Structural), MIX (Mixed), and OTH (Other).\n",
    "\n",
    "Currently commented out, it serves as a placeholder for integrating the custom classifier you intend to develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set path to checkpoint\n",
    "checkpoint_name = 'bert-large-uncased_train_10_4'; model_name = \"bert-large-uncased\"\n",
    "checkpoint_name = 'bert-for-patents_train_10_4'; model_name = \"anferico/bert-for-patents\" \n",
    "checkpoint_path = f\"/home/fantoni/patent-sentence-classification/models/finetuning/{checkpoint_name}.ckpt\"\n",
    "\n",
    "# Load Base Tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "print('\\nBase Tokenizer loaded succesfully.')\n",
    "\n",
    "# Load Base Model\n",
    "base_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "print('\\nBase model loaded succesfully.')\n",
    "\n",
    "# Load Finetuned Model\n",
    "model = PatentSentenceClassifier.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    model=base_model,\n",
    "    tokenizer=bert_tokenizer)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"\\nFinetuned model loaded succesfully. Using: '{checkpoint_name}'\")\n",
    "\n",
    "# Define Finetuned Tokenizer\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169764a",
   "metadata": {},
   "source": [
    "# 5. Import Claim\n",
    "\n",
    "In this section, we load a .txt file containing a single input claim to be processed by the patent simplification pipeline. Notably, the pipeline is designed to operate on one claim at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9c0a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A helmet system for removing condensation from a user's field of vision, comprising: a helmet shell having an anterior section, a posterior section, and a venting passage, wherein the helmet shell defines an internal cavity that is in fluid communication with a front portion of the venting passage, and wherein the internal cavity is configured to receive the user's head; a visor coupled with the helmet shell, wherein at least part of the visor defines part of the internal cavity; a humidity sensor positioned within the internal cavity of the helmet shell; and a ventilation system comprising: a base coupled with the helmet shell, wherein the base has a first venting aperture in fluid communication with a rear portion of the venting passage, a base cover coupled with the base, wherein the base cover has a second venting aperture, an air movement assembly disposed between the base and the base cover, wherein the air movement assembly provides fluid communication between the first venting aperture and the second venting aperture, a switch, a power source, and a circuit card comprising: a first input configured to receive a signal from the humidity sensor, a second input configured to receive a second signal from the switch, a first module configured to determine a first instruction for the air movement assembly based on the signal received from the humidity sensor, a second module configured to determine a second instruction for the air movement assembly based on the second signal received from the switch, a first output configured to transmit the first instruction to the air movement assembly, wherein activation of the air movement assembly based on the first instruction operates to remove condensation from the user's field of vision by moving a volume of air of the internal cavity of the helmet shell through the venting passage and moving the volume of air through the second venting aperture of the base cover between the anterior section and the posterior section, and a second output configured to transmit the second instruction to the air movement assembly, wherein the second instruction controls whether power is delivered to the air movement assembly and controls whether the air movement assembly directs air flow from the first venting aperture toward the second venting aperture or from the second venting aperture toward the first venting aperture.\n"
     ]
    }
   ],
   "source": [
    "# Patents\n",
    "filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/US8695121B2_A42B3.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/US11133720B2_H02K3.txt\"\n",
    "\n",
    "# Pavanello Patents\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/IT-201900008253-A1_B65G1-023.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/US-10733341-B1_G06F30-30.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2017216367-A1_C08J5-0405.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2019021161-A1_F16D65-12.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2019243958-A1_F16D55-288.txt\"\n",
    "#filepath =\"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2020058819-A1_B6078-1706.txt\"\n",
    "#filepath = \"/home/fantoni/patent-sentence-classification/data/claim_simplification/WO-2022144719-A1_B6078-261.txt\"\n",
    "\n",
    "with open(filepath, \"r\") as file:\n",
    "    input_text = file.read()\n",
    "    print(input_text)\n",
    "\n",
    "# Set file name\n",
    "filename = os.path.splitext(os.path.basename(filepath))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d9c98",
   "metadata": {},
   "source": [
    "# 6. Patent Claim Simplification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fa694",
   "metadata": {},
   "source": [
    "## 6.1 Extract Hierarchy\n",
    "\n",
    "This is the initial step of the patent simplification pipeline, where a prompt is used to insert indentation and reveal the hierarchical structure of the claim. The prompt is specifically designed to identify indentation levels that reflect the logical relationships and dependencies between different segments of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2ceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1. A helmet system for removing condensation from a user's field of vision, comprising:\n",
      ">>a helmet shell having an anterior section, a posterior section, and a venting passage, wherein the helmet shell defines an internal cavity that is in fluid communication with a front portion of the venting passage, and wherein the internal cavity is configured to receive the user's head;\n",
      ">>a visor coupled with the helmet shell, wherein at least part of the visor defines part of the internal cavity;\n",
      ">>a humidity sensor positioned within the internal cavity of the helmet shell; and\n",
      ">>a ventilation system comprising:\n",
      ">>>a base coupled with the helmet shell, wherein the base has a first venting aperture in fluid communication with a rear portion of the venting passage,\n",
      ">>>a base cover coupled with the base, wherein the base cover has a second venting aperture,\n",
      ">>>an air movement assembly disposed between the base and the base cover, wherein the air movement assembly provides fluid communication between the first venting aperture and the second venting aperture,\n",
      ">>>a switch,\n",
      ">>>a power source, and\n",
      ">>>a circuit card comprising:\n",
      ">>>>a first input configured to receive a signal from the humidity sensor,\n",
      ">>>>a second input configured to receive a second signal from the switch,\n",
      ">>>>a first module configured to determine a first instruction for the air movement assembly based on the signal received from the humidity sensor,\n",
      ">>>>a second module configured to determine a second instruction for the air movement assembly based on the second signal received from the switch,\n",
      ">>>>a first output configured to transmit the first instruction to the air movement assembly, wherein activation of the air movement assembly based on the first instruction operates to remove condensation from the user's field of vision by moving a volume of air of the internal cavity of the helmet shell through the venting passage and moving the volume of air through the second venting aperture of the base cover between the anterior section and the posterior section, and\n",
      ">>>>a second output configured to transmit the second instruction to the air movement assembly, wherein the second instruction controls whether power is delivered to the air movement assembly and controls whether the air movement assembly directs air flow from the first venting aperture toward the second venting aperture or from the second venting aperture toward the first venting aperture.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "parent_indices",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "parents",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fa02b7b9-bbf6-4046-b302-18a4e44dbdc5",
       "rows": [
        [
         "0",
         "1",
         "1. A helmet system for removing condensation from a user's field of vision, comprising:",
         "[]",
         "[]"
        ],
        [
         "1",
         "1.1",
         "a helmet shell having an anterior section, a posterior section, and a venting passage, wherein the helmet shell defines an internal cavity that is in fluid communication with a front portion of the venting passage, and wherein the internal cavity is configured to receive the user's head;",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "2",
         "1.2",
         "a visor coupled with the helmet shell, wherein at least part of the visor defines part of the internal cavity;",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "3",
         "1.3",
         "a humidity sensor positioned within the internal cavity of the helmet shell; and",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "4",
         "1.4",
         "a ventilation system comprising:",
         "['1']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\"]"
        ],
        [
         "5",
         "1.4.1",
         "a base coupled with the helmet shell, wherein the base has a first venting aperture in fluid communication with a rear portion of the venting passage,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "6",
         "1.4.2",
         "a base cover coupled with the base, wherein the base cover has a second venting aperture,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "7",
         "1.4.3",
         "an air movement assembly disposed between the base and the base cover, wherein the air movement assembly provides fluid communication between the first venting aperture and the second venting aperture,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "8",
         "1.4.4",
         "a switch,",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "9",
         "1.4.5",
         "a power source, and",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "10",
         "1.4.6",
         "a circuit card comprising:",
         "['1', '1.4']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:']"
        ],
        [
         "11",
         "1.4.6.1",
         "a first input configured to receive a signal from the humidity sensor,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "12",
         "1.4.6.2",
         "a second input configured to receive a second signal from the switch,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "13",
         "1.4.6.3",
         "a first module configured to determine a first instruction for the air movement assembly based on the signal received from the humidity sensor,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "14",
         "1.4.6.4",
         "a second module configured to determine a second instruction for the air movement assembly based on the second signal received from the switch,",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "15",
         "1.4.6.5",
         "a first output configured to transmit the first instruction to the air movement assembly, wherein activation of the air movement assembly based on the first instruction operates to remove condensation from the user's field of vision by moving a volume of air of the internal cavity of the helmet shell through the venting passage and moving the volume of air through the second venting aperture of the base cover between the anterior section and the posterior section, and",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ],
        [
         "16",
         "1.4.6.6",
         "a second output configured to transmit the second instruction to the air movement assembly, wherein the second instruction controls whether power is delivered to the air movement assembly and controls whether the air movement assembly directs air flow from the first venting aperture toward the second venting aperture or from the second venting aperture toward the first venting aperture.",
         "['1', '1.4', '1.4.6']",
         "[\"1. A helmet system for removing condensation from a user's field of vision, comprising:\", 'a ventilation system comprising:', 'a circuit card comprising:']"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 17
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>parent_indices</th>\n",
       "      <th>parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1. A helmet system for removing condensation f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>a helmet shell having an anterior section, a p...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>a visor coupled with the helmet shell, wherein...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>a humidity sensor positioned within the intern...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>a ventilation system comprising:</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.4.1</td>\n",
       "      <td>a base coupled with the helmet shell, wherein ...</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.4.2</td>\n",
       "      <td>a base cover coupled with the base, wherein th...</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.4.3</td>\n",
       "      <td>an air movement assembly disposed between the ...</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.4.4</td>\n",
       "      <td>a switch,</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.4.5</td>\n",
       "      <td>a power source, and</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.4.6</td>\n",
       "      <td>a circuit card comprising:</td>\n",
       "      <td>[1, 1.4]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.4.6.1</td>\n",
       "      <td>a first input configured to receive a signal f...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.4.6.2</td>\n",
       "      <td>a second input configured to receive a second ...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.4.6.3</td>\n",
       "      <td>a first module configured to determine a first...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.4.6.4</td>\n",
       "      <td>a second module configured to determine a seco...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.4.6.5</td>\n",
       "      <td>a first output configured to transmit the firs...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.4.6.6</td>\n",
       "      <td>a second output configured to transmit the sec...</td>\n",
       "      <td>[1, 1.4, 1.4.6]</td>\n",
       "      <td>[1. A helmet system for removing condensation ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text  \\\n",
       "0         1  1. A helmet system for removing condensation f...   \n",
       "1       1.1  a helmet shell having an anterior section, a p...   \n",
       "2       1.2  a visor coupled with the helmet shell, wherein...   \n",
       "3       1.3  a humidity sensor positioned within the intern...   \n",
       "4       1.4                   a ventilation system comprising:   \n",
       "5     1.4.1  a base coupled with the helmet shell, wherein ...   \n",
       "6     1.4.2  a base cover coupled with the base, wherein th...   \n",
       "7     1.4.3  an air movement assembly disposed between the ...   \n",
       "8     1.4.4                                          a switch,   \n",
       "9     1.4.5                                a power source, and   \n",
       "10    1.4.6                         a circuit card comprising:   \n",
       "11  1.4.6.1  a first input configured to receive a signal f...   \n",
       "12  1.4.6.2  a second input configured to receive a second ...   \n",
       "13  1.4.6.3  a first module configured to determine a first...   \n",
       "14  1.4.6.4  a second module configured to determine a seco...   \n",
       "15  1.4.6.5  a first output configured to transmit the firs...   \n",
       "16  1.4.6.6  a second output configured to transmit the sec...   \n",
       "\n",
       "     parent_indices                                            parents  \n",
       "0                []                                                 []  \n",
       "1               [1]  [1. A helmet system for removing condensation ...  \n",
       "2               [1]  [1. A helmet system for removing condensation ...  \n",
       "3               [1]  [1. A helmet system for removing condensation ...  \n",
       "4               [1]  [1. A helmet system for removing condensation ...  \n",
       "5          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "6          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "7          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "8          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "9          [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "10         [1, 1.4]  [1. A helmet system for removing condensation ...  \n",
       "11  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "12  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "13  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "14  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "15  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  \n",
       "16  [1, 1.4, 1.4.6]  [1. A helmet system for removing condensation ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indent text with prompt\n",
    "output_string, _ = prompt_chatgpt(input_text=input_text, input_context=None, prompt=indenting_prompt, model='gpt-3.5-turbo')\n",
    "print(output_string)\n",
    "\n",
    "# Extract hierarchy using a custom function and convert the output into a structured DataFrame\n",
    "# The extracted indentation levels are parsed into a tabular format for further processing.\n",
    "df = create_hierarchy(output_string)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d02b5f",
   "metadata": {},
   "source": [
    "## 6.2 Rephrasing, Splitting, and Classification\n",
    "\n",
    "In this section, we perform three main steps:\n",
    "1. Rephrasing \n",
    "2. Splitting  \n",
    "3. Classification\n",
    "\n",
    "These steps are applied conditionally based on the structure of the input:\n",
    "\n",
    "- **Case 1**: For short texts ending with a colon (e.g., *\"the camera comprises:\"*), we perform only classification (1).  \n",
    "  Rephrasing in this context introduce errors in the Bill of Materials (BoM) hierarchy.\n",
    "\n",
    "- **Case 2**: For longer texts that include a parent sentence, we apply all three steps (1), (2) and (3).\n",
    "\n",
    "- **Case 3**: For short, sentences without a parent node (i.e., root-level sentences), we perform only classification (1).\n",
    "\n",
    "**Note**: These steps are executed all at once to avoid running multiple prompts for the same sentence, thereby improving efficiency and reducing API cost.\n",
    "\n",
    "**Note**: Results may differ between ChatGPT (web interface) and the OpenAI API when using the same prompt.  \n",
    "See the related discussion: [OpenAI Community Thread](https://community.openai.com/t/different-results-same-prompt-on-openai-api-vs-chatgpt/1062995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82740ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "\n",
    "# Initialize ROUGE scorer with various n-gram options\n",
    "# reference: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
    "rouge_scorer = ROUGEScore(rouge_keys=('rouge1', 'rouge3', 'rouge5', 'rouge7', 'rouge9', 'rougeL'))\n",
    "\n",
    "# Model configuration\n",
    "CHATGPT_MODEL = 'gpt-4o' # 'gpt-3.5-turbo'\n",
    "TEMPERATURE = 0\n",
    "TOP_P = 1\n",
    "\n",
    "# Main processing loop\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Claim Texts\"):  \n",
    "    try:\n",
    "        input_text = row['text']\n",
    "        index = row['index']\n",
    "        word_count = len(re.findall(r'\\b\\w+\\b', input_text))\n",
    "        input_context = None\n",
    "        rephrasing_prompt = None\n",
    "        splitting_prompt = None\n",
    "\n",
    "        # Case 1: Short text ending with colon - classification only\n",
    "        # Rephrasing such sentences using contextual information can cause errors in the BOM hierarchy, \n",
    "        # so they are directly classified without rephrasing.\n",
    "        if input_text.endswith(':') and word_count <= 20:\n",
    "            \n",
    "            # Perform Classification\n",
    "            pred_class, probs = classify_text(model, input_text, device)\n",
    "            \n",
    "            # Calculate rouge scores\n",
    "            rouge_scores = calculate_rouge_scores_precision(input_text, input_text, rouge_scorer)\n",
    "            \n",
    "            # Append results using our new function\n",
    "            append_result_to_list(\n",
    "                results, \n",
    "                index, \n",
    "                input_text, \n",
    "                sentence=input_text, \n",
    "                pred_class=pred_class, \n",
    "                probs=probs, \n",
    "                rouge_scores=rouge_scores\n",
    "            )\n",
    "\n",
    "        # Case 2: Text with parents or long text - rephrasing, splitting and classification\n",
    "        elif row['parents'] or word_count >= 20:\n",
    "            \n",
    "            # 1. Get context from parent claims if available\n",
    "            n_parents = 1  # Number of parent claims to include\n",
    "            input_context = ' '.join(row['parents'][-n_parents:]) if row['parents'] else ' '\n",
    "            \n",
    "            # 2. Rephrase text using context\n",
    "            rephrased_text, rephrasing_prompt = prompt_chatgpt(input_text, input_context, rephrasing_with_context_prompt, CHATGPT_MODEL, TEMPERATURE, TOP_P)\n",
    "            \n",
    "            # 3. Split text into sub-sentences\n",
    "            split_text, splitting_prompt = prompt_chatgpt(rephrased_text, input_context, splitting_with_context_prompt, CHATGPT_MODEL, TEMPERATURE, TOP_P)\n",
    "            \n",
    "            # Validate output format\n",
    "            if not split_text:\n",
    "                raise ValueError(\"Output is empty.\")\n",
    "    \n",
    "            try:\n",
    "                split_text = ast.literal_eval(split_text)\n",
    "            except (SyntaxError, ValueError) as e:\n",
    "                raise ValueError(f\"Output not in list format: {e}\")\n",
    "            \n",
    "            # 4. Process each sub-sentence\n",
    "            for sent in split_text:\n",
    "                # Classify sub-sentence\n",
    "                pred_class, probs = classify_text(model, sent, device)\n",
    "                \n",
    "                # Calculate rouge scores\n",
    "                rouge_scores = calculate_rouge_scores_precision(sent, input_text, rouge_scorer)\n",
    "                \n",
    "                # Append results using our new function\n",
    "                append_result_to_list(\n",
    "                    results, \n",
    "                    index, \n",
    "                    input_text, \n",
    "                    context=input_context,\n",
    "                    rephrasing_prompt=rephrasing_prompt,\n",
    "                    rephrased_text=rephrased_text,\n",
    "                    splitting_prompt=splitting_prompt,\n",
    "                    sentence=sent,\n",
    "                    pred_class=pred_class, \n",
    "                    probs=probs, \n",
    "                    rouge_scores=rouge_scores\n",
    "                )\n",
    "\n",
    "        # Case 3: Short sentences without parents, that is short root sentences - classification only\n",
    "        else:\n",
    "            # Perform Classification\n",
    "            pred_class, probs = classify_text(model, input_text, device)\n",
    "            \n",
    "            # Calculate rouge scores\n",
    "            rouge_scores = calculate_rouge_scores_precision(input_text, input_text, rouge_scorer)\n",
    "            \n",
    "            # Append results using our new function\n",
    "            append_result_to_list(\n",
    "                results, \n",
    "                index, \n",
    "                input_text, \n",
    "                sentence=input_text, \n",
    "                pred_class=pred_class, \n",
    "                probs=probs, \n",
    "                rouge_scores=rouge_scores\n",
    "            )\n",
    "\n",
    "    # Handle errors\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing claim {row['index']}: {str(e)}\")\n",
    "        append_result_to_list(\n",
    "            results,\n",
    "            index,\n",
    "            input_text,\n",
    "            error=str(e)\n",
    "        )\n",
    "\n",
    "# Create DataFrame from results and save to Excel\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_excel(f\"/home/fantoni/patent-sentence-classification/results/claim_simplification/{filename}_{CHATGPT_MODEL}.xlsx\", index=False)   \n",
    "print(f\"Results saved to /home/fantoni/patent-sentence-classification/results/claim_simplification/{filename}_{CHATGPT_MODEL}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa546c",
   "metadata": {},
   "source": [
    "## 6.3 Visualization\n",
    "\n",
    "In this section, we generate an HTML document to enhance the visualization of both the hierarchical structure and the classification results. This interactive output helps to better interpret and validate the results of the simplification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Excel file path\n",
    "excel_path = \"/home/fantoni/patent-sentence-classification/results/claim_simplification/WO-2020058819-A1_B6078-1706_gpt-4o.xlsx\"\n",
    "#excel_path = \"/home/fantoni/patent-sentence-classification/results/claim_simplification/WO-2019021161-A1_F16D65-12_gpt-4o.xlsx\"\n",
    "#excel_path = \"/home/fantoni/patent-sentence-classification/results/claim_simplification/WO-2019243958-A1_F16D55-288_gpt-4o.xlsx\"\n",
    "#excel_path = \"/home/fantoni/patent-sentence-classification/results/claim_simplification/IT-201900008253-A1_B65G1-023_gpt-4o.xlsx\"\n",
    "#excel_path = \"/home/fantoni/patent-sentence-classification/results/claim_simplification/US8695121B2_A42B3_gpt-4o.xlsx\"\n",
    "\n",
    "# Set file name\n",
    "filename = os.path.splitext(os.path.basename(excel_path))[0]\n",
    "\n",
    "# Get original text\n",
    "txt_path = f\"/home/fantoni/patent-sentence-classification/data/claim_simplification/{\"_\".join(filename.split('_')[:-1])}.txt\"\n",
    "with open(txt_path, \"r\") as file:\n",
    "    original_claim = file.read()\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(excel_path, dtype={\"index\": str})\n",
    "\n",
    "# Create level of indentation\n",
    "df['level'] = df['index'].apply(lambda x: len(str(x).split('.')))\n",
    "\n",
    "# Define background colors for classes\n",
    "class_colors = {\n",
    "    'FUN': '#ffcccc',   # reddish\n",
    "    'STR': '#cce5ff',   # blueish\n",
    "    'MIX': '#ccffcc',   # greenish\n",
    "    'OTH': '#e0e0e0'    # greyish\n",
    "}\n",
    "\n",
    "# Create color legend HTML\n",
    "legend_html = \"\"\"\n",
    "<div class=\"section\">\n",
    "    <summary>Legend</summary>\n",
    "    <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "        <li style=\"background-color:#ffcccc; padding:4px; margin:2px 0; display: inline-block; width: 100px;\">FUN</li>\n",
    "        <li style=\"background-color:#cce5ff; padding:4px; margin:2px 0; display: inline-block; width: 100px;\">STR</li>\n",
    "        <li style=\"background-color:#ccffcc; padding:4px; margin:2px 0; display: inline-block; width: 100px;\">MIX</li>\n",
    "        <li style=\"background-color:#e0e0e0; padding:4px; margin:2px 0; display: inline-block; width: 100px;\">OTH</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Create html for original text\n",
    "original_claim_html = \"<ul>\"\n",
    "original_claim_html += f\"<li>{original_claim}</li>\"\n",
    "original_claim_html += \"</ul>\"\n",
    "\n",
    "# Create html for simplified  text\n",
    "grouped = df.dropna(subset=[\"sentence\"]).groupby(\"level\") # Group by 'level' for collapsible sentence sections\n",
    "\n",
    "sentence_html = \"\"\n",
    "for level, group in grouped:\n",
    "    indent = int(level) * 40\n",
    "    sentence_html += f\"<details style='margin-left:{indent}px'>\"\n",
    "    sentence_html += \"<summary></summary><ul style='list-style-type:none;'>\"\n",
    "\n",
    "    # Track the last seen prefix at this level\n",
    "    last_index = None\n",
    "    for _, row in group.iterrows():\n",
    "        \n",
    "        current_index = row['index']\n",
    "\n",
    "        # Add space if prefix changed\n",
    "        if last_index is not None and current_index != last_index:\n",
    "            sentence_html += \"<hr style='border: none; border-top: 1px solid #888; margin: 10px 0;'>\"\n",
    "        last_index = current_index\n",
    "\n",
    "        bg_color = class_colors.get(row['pred_class'], '#ffffff')\n",
    "        sentence_html += (\n",
    "            f\"<li style='background-color:{bg_color}; padding:4px; margin:2px 0;'>\"\n",
    "            f\"{row['sentence']}</li>\"\n",
    "        )\n",
    "\n",
    "    sentence_html += \"</ul></details>\"\n",
    "\n",
    "# Combine everything into final HTML\n",
    "html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Claim Visualization {filename}</title>\n",
    "    <style>\n",
    "        .section {{\n",
    "            margin-bottom: 20px;\n",
    "        }}\n",
    "        summary {{\n",
    "            font-weight: bold;\n",
    "            cursor: pointer;\n",
    "        }}\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            margin: 20px;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"section\">\n",
    "        <details open>\n",
    "            <summary>Original Text</summary>\n",
    "            {original_claim_html}\n",
    "        </details>\n",
    "    </div>\n",
    "    {legend_html}\n",
    "    <div class=\"section\">\n",
    "        <details open>\n",
    "            <summary>Simplified Text</summary>\n",
    "            {sentence_html}\n",
    "        </details>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save the HTML to a file\n",
    "html_file_path = f\"/home/fantoni/patent-sentence-classification/results/claim_simplification/{filename}.html\"\n",
    "with open(html_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"HTML saved to {html_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
